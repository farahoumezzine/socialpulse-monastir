"""
SocialPulse Monastir - Dashboard Streamlit
==========================================
Interface web pour l'analyse de sentiment et la dÃ©tection d'Ã©vÃ©nements.
"""
import streamlit as st
import requests
import pandas as pd
from datetime import datetime
import plotly.express as px

# Import du module de dÃ©tection d'Ã©vÃ©nements (assure-toi que topic_engine.py est prÃ©sent)
try:
    from topic_engine import TopicEventAnalyzer
    TOPIC_MODULE_AVAILABLE = True
except ImportError:
    TOPIC_MODULE_AVAILABLE = False

# ============================================================
# CONFIGURATION
# ============================================================
st.set_page_config(
    page_title="SocialPulse Monastir",
    page_icon="ğŸ“Š",
    layout="wide"
)

API_URL = "http://localhost:5000"

# ============================================================
# FONCTIONS
# ============================================================
def check_api():
    """VÃ©rifie si l'API est en ligne."""
    try:
        response = requests.get(f"{API_URL}/health", timeout=2)
        return response.status_code == 200
    except:
        return False

def analyze_text(text, model="bert"):
    """Analyse le sentiment d'un texte."""
    try:
        response = requests.post(
            f"{API_URL}/predict",
            json={"text": text, "model": model},
            timeout=10
        )
        return response.json()
    except Exception as e:
        return {"success": False, "error": str(e)}

def analyze_batch(texts, model="bert"):
    """Analyse plusieurs textes."""
    try:
        response = requests.post(
            f"{API_URL}/predict/batch",
            json={"texts": texts, "model": model},
            timeout=30
        )
        return response.json()
    except Exception as e:
        return {"success": False, "error": str(e)}

# ============================================================
# INTERFACE
# ============================================================

# Header
st.title("ğŸ“Š SocialPulse Monastir")
st.markdown("**Analyse de Sentiment & DÃ©tection d'Ã‰vÃ©nements en Darija Tunisien**")
st.markdown("---")

# Sidebar
with st.sidebar:
    st.header("âš™ï¸ Configuration")
    
    # API Status
    api_online = check_api()
    if api_online:
        st.success("ğŸŸ¢ API en ligne")
    else:
        st.error("ğŸ”´ API hors ligne")
        st.warning("Lancez l'API avec:  `python src/api.py`")
    
    st.markdown("---")
    
    # Model selection
    model = st.selectbox(
        "ModÃ¨le Sentiment",
        ["bert", "sklearn"],
        format_func=lambda x: "ğŸ¤– BERT (CAMeLBERT)" if x == "bert" else "ğŸ“ˆ Naive Bayes"
    )
    
    st.markdown("---")
    
    # Info
    st.markdown("### ğŸ“ Ã€ propos")
    st.markdown("""
    **SocialPulse Monastir**  
    Projet NLP - Surveillance Urbaine
    """)

# Main content
# Ajout du nouvel onglet "DÃ©tection d'Ã‰vÃ©nements"
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ” Analyse Simple", "ğŸ“‹ Analyse en Lot", "ğŸ“ˆ Statistiques", "ğŸŒ DÃ©tection d'Ã‰vÃ©nements"])

# ============================================================
# TAB 1: Analyse Simple
# ============================================================
with tab1:
    st.header("ğŸ” Analyser un texte")
    
    # Input
    text_input = st.text_area(
        "Entrez votre texte en Darija ou en Arabe",
        placeholder="Exemples:\n- Ø§Ù„Ø¬Ùˆ Ø±Ø§Ø¦Ø¹ ÙÙŠ Ø§Ù„Ù…Ù†Ø³ØªÙŠØ±\n- Ù…Ø´ÙƒÙ„Ø© ÙƒØ¨ÙŠØ±Ø© ÙˆØ²Ø­Ù…Ø©\n- jaw rawaa barcha",
        height=120
    )
    
    col1, col2 = st.columns([1, 4])
    with col1:
        analyze_btn = st.button("ğŸ” Analyser", type="primary", use_container_width=True)
    
    # Results
    if analyze_btn and text_input:
        if not api_online:
            st.error("âŒ L'API n'est pas disponible. Lancez `python src/api.py`")
        else:
            with st.spinner("Analyse en cours..."):
                result = analyze_text(text_input, model)
            
            if result.get("success"):
                st.markdown("---")
                st.subheader("ğŸ“Š RÃ©sultat")
                
                # Sentiment display
                sentiment = result["sentiment"]
                confidence = result["confidence"]
                emoji_map = {"positive": "ğŸ˜Š", "negative": "ğŸ˜", "neutral": "ğŸ˜"}
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.markdown(f"### {emoji_map.get(sentiment, 'ğŸ˜')}")
                    st.markdown(f"**{sentiment.upper()}**")
                
                with col2:
                    st.metric("Confiance", f"{confidence}%")
                
                with col3:
                    st.metric("ModÃ¨le", "BERT" if result["model_used"] == "bert" else "Naive Bayes")
                
                # Probabilities
                st.markdown("#### ProbabilitÃ©s")
                probs = result["probabilities"]
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.progress(probs.get("positive", 0) / 100)
                    st.caption(f"âœ… Positive: {probs.get('positive', 0)}%")
                with col2:
                    st.progress(probs.get("neutral", 0) / 100)
                    st.caption(f"âšª Neutral: {probs.get('neutral', 0)}%")
                with col3:
                    st.progress(probs.get("negative", 0) / 100)
                    st.caption(f"âŒ Negative: {probs.get('negative', 0)}%")
            else:
                st.error(f"âŒ Erreur:  {result.get('error', 'Erreur inconnue')}")
    
    elif analyze_btn and not text_input:
        st.warning("âš ï¸ Veuillez entrer un texte Ã  analyser")

# ============================================================
# TAB 2: Analyse en Lot
# ============================================================
with tab2:
    st.header("ğŸ“‹ Analyse en lot")
    
    batch_input = st.text_area(
        "Entrez plusieurs textes (un par ligne)",
        placeholder="Ø§Ù„Ø¬Ùˆ Ø±Ø§Ø¦Ø¹\nÙ…Ø´ÙƒÙ„Ø© ÙƒØ¨ÙŠØ±Ø©\nØºØ¯ÙˆØ© ÙÙ…Ø§ Ù…Ø§ØªØ´",
        height=150
    )
    
    batch_btn = st.button("ğŸ” Analyser tout", type="primary", key="batch_btn")
    
    if batch_btn and batch_input:
        if not api_online:
            st.error("âŒ L'API n'est pas disponible")
        else:
            texts = [t.strip() for t in batch_input.split("\n") if t.strip()]
            
            if texts:
                with st.spinner(f"Analyse de {len(texts)} textes..."):
                    result = analyze_batch(texts, model)
                
                if result.get("success"):
                    st.markdown("---")
                    
                    # Summary
                    st.subheader("ğŸ“Š RÃ©sumÃ©")
                    summary = result["summary"]
                    
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("Total", summary["total"])
                    with col2:
                        st.metric("âœ… Positive", summary["positive"])
                    with col3:
                        st.metric("âšª Neutral", summary["neutral"])
                    with col4:
                        st.metric("âŒ Negative", summary["negative"])
                    
                    # Chart
                    chart_data = pd.DataFrame({
                        "Sentiment": ["Positive", "Neutral", "Negative"],
                        "Count": [summary["positive"], summary["neutral"], summary["negative"]]
                    })
                    st.bar_chart(chart_data.set_index("Sentiment"))
                    
                    # Table
                    st.subheader("ğŸ“‹ DÃ©tails")
                    df = pd.DataFrame(result["results"])
                    if not df.empty:
                        df = df[["text", "sentiment", "confidence"]]
                        df.columns = ["Texte", "Sentiment", "Confiance (%)"]
                        st.dataframe(df, use_container_width=True)
                else:
                    st.error(f"âŒ Erreur: {result.get('error')}")
            else:
                st.warning("âš ï¸ Aucun texte Ã  analyser")

# ============================================================
# TAB 3: Statistiques
# ============================================================
with tab3:
    st.header("ğŸ“ˆ Statistiques")
    
    if not api_online:
        st.warning("âš ï¸ L'API doit Ãªtre en ligne pour afficher les statistiques")
    else:
        st.info("ğŸ’¡ Analysez des textes pour voir les statistiques ici")
        
        # Example analysis
        st.markdown("### ğŸ§ª Test rapide")
        
        if st.button("Lancer un test avec des exemples"):
            test_texts = [
                "Ø§Ù„Ø¬Ùˆ Ø±Ø§Ø¦Ø¹ ÙÙŠ Ø§Ù„Ù…Ù†Ø³ØªÙŠØ±",
                "Ù…Ø´ÙƒÙ„Ø© ÙƒØ¨ÙŠØ±Ø© ÙˆØ²Ø­Ù…Ø©",
                "ØºØ¯ÙˆØ© ÙÙ…Ø§ Ù…Ø§ØªØ´",
                "Ø§Ù„Ù…Ù‡Ø±Ø¬Ø§Ù† ÙƒØ§Ù† Ù…Ù…ØªØ§Ø²",
                "Ø§Ù„ØªØ±Ø§Ù†Ø³Ø¨ÙˆØ± Ø®Ø§ÙŠØ¨ Ø¨Ø±Ø´Ø§",
                "jaw rawaa barcha",
                "zahma kbira"
            ]
            
            with st.spinner("Analyse des exemples..."):
                result = analyze_batch(test_texts, model)
            
            if result.get("success"):
                summary = result["summary"]
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("#### Distribution")
                    chart_data = pd.DataFrame({
                        "Sentiment": ["Positive", "Neutral", "Negative"],
                        "Count":  [summary["positive"], summary["neutral"], summary["negative"]]
                    })
                    st.bar_chart(chart_data.set_index("Sentiment"))
                
                with col2:
                    st.markdown("#### RÃ©sultats")
                    for r in result["results"]:
                        emoji = {"positive": "âœ…", "negative": "âŒ", "neutral": "âšª"}.get(r["sentiment"], "â€¢")
                        st.write(f"{emoji} {r['text'][:30]}...  â†’ **{r['sentiment']}** ({r['confidence']}%)")

# ============================================================
# TAB 4: DÃ©tection d'Ã‰vÃ©nements (NOUVEAU)
# ============================================================
with tab4:
    st.header("ğŸŒ DÃ©tection d'Ã‰vÃ©nements & Sujets")
    st.markdown("Identifiez les tendances Ã©mergentes et les pics anormaux de discussion Ã  Monastir.")

    if not TOPIC_MODULE_AVAILABLE:
        st.error("âŒ Le module `topic_engine.py` est manquant. Veuillez l'ajouter au dossier.")
    else:
        # Simulation de donnÃ©es pour la dÃ©mo si pas de CSV chargÃ©
        # Dans un vrai cas, tu chargerais Ã§a depuis ton API ou une Base de DonnÃ©es
        st.info("ğŸ’¡ Chargez un fichier CSV contenant une colonne 'text' et 'created_at' pour une analyse rÃ©elle.")
        
        uploaded_file = st.file_uploader("Charger un dataset CSV (Optionnel)", type=["csv"])
        
        if uploaded_file is not None:
            df_events = pd.read_csv(uploaded_file)
            st.success(f"Dataset chargÃ© : {len(df_events)} lignes")
        else:
            # CrÃ©ation de fausses donnÃ©es pour tester l'interface
            dates = pd.date_range(start="2023-10-01", periods=100, freq="H")
            data_fake = {
                "text": ["Traffic jam center"]*20 + ["Beautiful beach"]*30 + ["Power outage"]*10 + ["Normal day"]*40,
                "created_at": dates
            }
            df_events = pd.DataFrame(data_fake)
            st.caption("âš ï¸ Utilisation de donnÃ©es de dÃ©monstration (Trafic, Plage, Panne).")

        # Bouton d'analyse
        if st.button("ğŸš€ Lancer l'analyse des tendances (Topics)", type="primary"):
            if 'text' not in df_events.columns:
                 st.error("Le CSV doit contenir une colonne 'text'.")
            else:
                with st.spinner('Analyse sÃ©mantique en cours avec BERTopic (Ceci peut prendre du temps)...'):
                    try:
                        analyzer = TopicEventAnalyzer()
                        
                        # PrÃ©paration des donnÃ©es
                        docs = df_events['text'].astype(str).tolist()
                        # Si 'created_at' n'existe pas, on simule des dates
                        if 'created_at' in df_events.columns:
                            timestamps = pd.to_datetime(df_events['created_at']).tolist()
                        else:
                            timestamps = pd.date_range(start="2023-01-01", periods=len(docs)).tolist()

                        # ExÃ©cution
                        topics, topic_info, topics_over_time = analyzer.extract_topics(docs, timestamps)
                        
                        # Sauvegarde Session State
                        st.session_state['topic_data'] = {
                            'model': analyzer.topic_model,
                            'topics_over_time': topics_over_time,
                            'analyzer': analyzer
                        }
                        st.success("Analyse terminÃ©e !")
                    except Exception as e:
                        st.error(f"Erreur durant l'analyse : {str(e)}")

        # Affichage des rÃ©sultats
        if 'topic_data' in st.session_state:
            data = st.session_state['topic_data']
            tm = data['model']
            topics_over_time = data['topics_over_time']
            analyzer = data['analyzer']

            # Section 1: Visualisation des Topics
            st.subheader("ğŸ“Œ Sujets dominants")
            try:
                fig_topics = tm.visualize_barchart(top_n_topics=8)
                st.plotly_chart(fig_topics, use_container_width=True)
            except Exception as e:
                st.warning("Pas assez de donnÃ©es pour gÃ©nÃ©rer le graphique des topics.")

            # Section 2: Ã‰volution Temporelle
            st.subheader("ğŸ“ˆ Ã‰volution temporelle")
            try:
                fig_time = tm.visualize_topics_over_time(topics_over_time)
                st.plotly_chart(fig_time, use_container_width=True)
            except Exception as e:
                 st.warning("Impossible de visualiser l'Ã©volution temporelle (donnÃ©es insufisantes ?).")

            # Section 3: Alertes
            st.subheader("ğŸš¨ Alertes & Anomalies")
            alerts_df = analyzer.detect_anomalies(topics_over_time)
            
            if not alerts_df.empty:
                st.error(f"{len(alerts_df)} Ã©vÃ©nements anormaux dÃ©tectÃ©s !")
                st.dataframe(alerts_df, use_container_width=True)
            else:
                st.success("Aucune anomalie majeure dÃ©tectÃ©e sur la pÃ©riode.")

# Footer
st.markdown("---")
st.markdown("**SocialPulse Monastir** | 2025")
