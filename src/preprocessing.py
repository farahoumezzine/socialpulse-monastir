import emoji
import re
import json
import random
import os

# ============================================
# 1.  EMOJI SENTIMENT MAPPING (Tableau d'emojis)
# ============================================
EMOJI_SENTIMENT_MAP = {
    # Positif
    'üòÄ': {'sentiment': 'positive', 'score': 1, 'label': 'farhan'},
    'üòä': {'sentiment': 'positive', 'score': 1, 'label': 'farhan'},
    'üòç': {'sentiment': 'positive', 'score': 1, 'label': 'hob'},
    'ü•∞': {'sentiment': 'positive', 'score': 1, 'label': 'hob'},
    '‚ù§Ô∏è': {'sentiment': 'positive', 'score': 1, 'label': 'hob'},
    'üíï': {'sentiment': 'positive', 'score': 1, 'label': 'hob'},
    'üëç': {'sentiment': 'positive', 'score': 0.8, 'label': 'behi'},
    'üéâ': {'sentiment': 'positive', 'score': 1, 'label': 'jaw'},
    'üî•': {'sentiment': 'positive', 'score': 0.9, 'label': 'nar'},
    'üí™': {'sentiment': 'positive', 'score': 0.8, 'label': 'kwi'},
    '‚ú®': {'sentiment': 'positive', 'score': 0.7, 'label': 'jaw'},
    'üôè': {'sentiment': 'positive', 'score': 0.7, 'label': 'chokr'},
    'üòÇ': {'sentiment': 'positive', 'score': 0.8, 'label': 'edahek'},
    'ü§£': {'sentiment': 'positive', 'score': 0.8, 'label': 'edahek'},
    'üëè': {'sentiment': 'positive', 'score': 0.9, 'label': 'bravo'},
    'ü•≥': {'sentiment': 'positive', 'score': 1, 'label': 'jaw'},
    'üòé': {'sentiment': 'positive', 'score': 0.7, 'label': 'jaw'},
    'üåü': {'sentiment': 'positive', 'score': 0.8, 'label': 'jaw'},
    'üé∂': {'sentiment': 'positive', 'score': 0.6, 'label': 'jaw'},
      # Positifs suppl√©mentaires
    'üíÉ':  {'sentiment': 'positive', 'score': 0.9, 'label': 'jaw'},
    'üòå': {'sentiment': 'positive', 'score': 0.7, 'label': 'mertah'},
    'üíô': {'sentiment': 'positive', 'score': 1, 'label': 'hob'},
    'üåû': {'sentiment': 'positive', 'score': 0.8, 'label': 'chams'},
    'üôå':  {'sentiment': 'positive', 'score': 0.9, 'label': 'tok_aleha'},
    '‚ù§':  {'sentiment': 'positive', 'score': 1, 'label': 'hob'},
    'üåÖ': {'sentiment': 'positive', 'score': 0.8, 'label': 'ghroub'},
    'üèÜ': {'sentiment': 'positive', 'score': 1, 'label': 'rebeh'},
    # N√©gatif
    'üò¢': {'sentiment': 'negative', 'score': -0.8, 'label': 'hzin'},
    'üò≠': {'sentiment': 'negative', 'score': -1, 'label': 'yebki'},
    'üò°': {'sentiment': 'negative', 'score': -1, 'label': 'metghachech'},
    'üò†': {'sentiment': 'negative', 'score': -0.9, 'label': 'metghachech'},
    'ü§¨': {'sentiment': 'negative', 'score': -1, 'label': 'metghachech'},
    'üëé': {'sentiment': 'negative', 'score': -0.8, 'label': 'mouch_behi'},
    'üíî': {'sentiment': 'negative', 'score': -0.9, 'label': '9alb_maksour'},
    'üò§': {'sentiment': 'negative', 'score': -0.7, 'label': 'metghachech'},
    'üò©': {'sentiment': 'negative', 'score': -0.8, 'label': 'taab'},
    'üò´': {'sentiment': 'negative', 'score': -0.9, 'label': 'taab'},
    'üôÑ': {'sentiment': 'negative', 'score': -0.5, 'label': 'mech_ajbou'},
    'üòí': {'sentiment': 'negative', 'score': -0.6, 'label': 'mech_ajbou'},
    'üòû': {'sentiment': 'negative', 'score': -0.7, 'label': 'hzin'},
    'üòî': {'sentiment': 'negative', 'score': -0.6, 'label': 'hzin'},
      # N√©gatifs suppl√©mentaires
    'ü§¢': {'sentiment': 'negative', 'score': -0.9, 'label':  'mokref'},
    'üòï': {'sentiment': 'negative', 'score': -0.5, 'label': 'mech_fehim'},
    'üòì': {'sentiment': 'negative', 'score': -0.6, 'label': 'taab'},
    'ü•¥':  {'sentiment': 'negative', 'score': -0.5, 'label': 'mouch_merteh'},
    # Neutre
    'ü§î': {'sentiment': 'neutral', 'score': 0, 'label': 'yfaker'},
    'ü§∑': {'sentiment': 'neutral', 'score': 0, 'label': 'marefch'},
    'üìç': {'sentiment': 'neutral', 'score': 0, 'label': 'blasa'},
    'üì∏': {'sentiment': 'neutral', 'score': 0, 'label': 'taswira'},
    'üöó': {'sentiment': 'neutral', 'score': 0, 'label': 'karhba'},
    'üèñÔ∏è': {'sentiment': 'neutral', 'score': 0.3, 'label': 'bhar'},
    '‚öΩ': {'sentiment': 'neutral', 'score': 0.2, 'label': 'koura'},
    'üè®': {'sentiment': 'neutral', 'score': 0, 'label': 'hotel'},
    'üèõ': {'sentiment': 'neutral', 'score': 0, 'label': 'maalem'},
    # Neutres suppl√©mentaires
    '‚òï': {'sentiment': 'neutral', 'score': 0.2, 'label': 'kahwa'},
    'üèÄ': {'sentiment': 'neutral', 'score': 0.2, 'label': 'basket'},
    'üõ¥': {'sentiment': 'neutral', 'score': 0, 'label': 'trotinette'},
    'üìÖ':  {'sentiment': 'neutral', 'score': 0, 'label': 'date'},
    'üìΩ': {'sentiment': 'neutral', 'score': 0, 'label': 'film'},
    'üìñ': {'sentiment': 'neutral', 'score': 0.2, 'label': 'kteb'},
    'üé§': {'sentiment': 'neutral', 'score': 0.3, 'label': 'micro'},
    'üòê': {'sentiment': 'neutral', 'score': 0, 'label': 'normal'},
    'üìö': {'sentiment': 'neutral', 'score': 0.2, 'label': 'ktob'},
    'üí°': {'sentiment': 'neutral', 'score': 0.1, 'label': 'fikra'},
    'üé≠': {'sentiment': 'neutral', 'score': 0.3, 'label': 'masrah'},
    'üé®': {'sentiment': 'neutral', 'score': 0.4, 'label': 'fann'},
    'ü•¨': {'sentiment': 'neutral', 'score': 0, 'label': 'khodhra'},
    'üç≥':  {'sentiment': 'neutral', 'score': 0.1, 'label': 'tabkh'},
    'üë©': {'sentiment': 'neutral', 'score': 0, 'label': 'mra'},
    'üì¢': {'sentiment': 'neutral', 'score': 0, 'label': 'ilan'},
}

# ============================================
# EMOJIS CONTEXTUELS (Ambigus)
# ============================================
CONTEXT_DEPENDENT_EMOJIS = {
    'üîä': {
        'positive_context': ['festival', 'fete', 'jaw', 'ambiance', 'musique', 'hbel', 'rawaa', 'heyel', 'concert', 'party', 'sahriya', 'match'],
        'negative_context': ['bruit', 'kwi', 'derangement', 'sot', 'ali', 'barcha', 'mochkla', 'hess'],
        'positive_label': 'ambiance',
        'negative_label': 'sot_ali',
        'neutral_label': 'sot',
        'positive_score': 0.6,
        'negative_score':  -0.5,
    },
    'üöß':  {
        'positive_context':  ['tajdid', 'isalhou', 'tahsin', 'travaux', 'amelioration'],
        'negative_context': ['zahma', 'trafic', 'mochkla', 'nestanaw', 'retard', 'habsin', 'msaker'],
        'positive_label': 'islah',
        'negative_label': 'achghal',
        'neutral_label': 'achghal',
        'positive_score': 0.3,
        'negative_score':  -0.4,
    },
    'üò¨': {
        'positive_context': ['hbel', 'rawaa', 'excitement', 'suspense', 'jaw'],
        'negative_context': ['mochkla', 'khayeb', 'ghalat', 'fdhiha'],
        'positive_label': 'excite',
        'negative_label':  'mech_merta7',
        'neutral_label': 'mech_merta7',
        'positive_score': 0.4,
        'negative_score':  -0.4,
    },
    'üåô': {
        'positive_context': ['festival', 'sahriya', 'fete', 'lila', 'ramadan', 'sohour', 'ambiance', 'concert'],
        'negative_context': ['nejmech_norked', 'insomnie', 'taab', 'mochkla','jenich_noum'],
        'positive_label': 'lila_helwa',
        'negative_label':  'lil',
        'neutral_label': 'lil',
        'positive_score': 0.5,
        'negative_score':  -0.3,
    },
    '‚è∞': {
        'positive_context': ['wakt', 'bda', 'commence', 'rappel'],
        'negative_context': ['retard', 'makher', 'fout', 'fisa', 'testana', 'mochkla'],
        'positive_label': 'wa9t',
        'negative_label':  'takhir',
        'neutral_label': 'wa9t',
        'positive_score': 0.2,
        'negative_score':  -0.4,
    },
}


def get_emoji_sentiment_with_context(emoji_char, text):
    """
    D√©termine le sentiment d'un emoji selon le contexte de la phrase.
    
    Args:
        emoji_char: L'emoji √† analyser
        text: Le texte complet contenant l'emoji
    
    Returns:
        dict: {'sentiment': str, 'score':  float, 'label': str}
    """
    # Si l'emoji n'est pas ambigu, utiliser le mapping normal
    if emoji_char not in CONTEXT_DEPENDENT_EMOJIS:
        if emoji_char in EMOJI_SENTIMENT_MAP:
            info = EMOJI_SENTIMENT_MAP[emoji_char]
            return {
                'sentiment': info['sentiment'],
                'score': info['score'],
                'label': info['label']
            }
        # Emoji inconnu
        return {'sentiment': 'neutral', 'score': 0, 'label': 'emoji'}
    
    # Emoji ambigu - analyser le contexte
    context_info = CONTEXT_DEPENDENT_EMOJIS[emoji_char]
    text_lower = text.lower()
    
    # Compter les mots de contexte positif et n√©gatif
    positive_count = sum(1 for word in context_info['positive_context'] if word in text_lower)
    negative_count = sum(1 for word in context_info['negative_context'] if word in text_lower)
    
    # D√©cider selon le contexte dominant
    if positive_count > negative_count:
        return {
            'sentiment': 'positive',
            'score': context_info['positive_score'],
            'label': context_info['positive_label']
        }
    elif negative_count > positive_count:
        return {
            'sentiment': 'negative',
            'score': context_info['negative_score'],
            'label': context_info['negative_label']
        }
    else: 
        # Contexte neutre ou √©galit√©
        return {
            'sentiment': 'neutral',
            'score': 0,
            'label': context_info['neutral_label']
        }
    
def extract_emoji_sentiment(text):
    """
    Extrait les emojis du texte et calcule un score de sentiment agr√©g√©.
    Utilise l'analyse contextuelle pour les emojis ambigus. 
    """
    found_emojis = []
    total_score = 0
    emoji_count = 0
    
    for char in text:
        if char in EMOJI_SENTIMENT_MAP or char in CONTEXT_DEPENDENT_EMOJIS:
            # Utiliser l'analyse contextuelle
            emoji_info = get_emoji_sentiment_with_context(char, text)
            found_emojis.append({
                'emoji': char,
                'sentiment': emoji_info['sentiment'],
                'score': emoji_info['score'],
                'label_darija': emoji_info['label']
            })
            total_score += emoji_info['score']
            emoji_count += 1
        elif emoji. is_emoji(char):
            # Emoji non mapp√© - trait√© comme neutre
            found_emojis.append({
                'emoji':  char,
                'sentiment': 'neutral',
                'score':  0,
                'label_darija': 'emoji'
            })
            emoji_count += 1
    
    avg_score = total_score / emoji_count if emoji_count > 0 else 0
    
    return {
        'emojis': found_emojis,
        'emoji_count': emoji_count,
        'total_score': round(total_score, 2),
        'avg_score': round(avg_score, 2),
        'dominant_sentiment': 'positive' if avg_score > 0.2 else ('negative' if avg_score < -0.2 else 'neutral')
    }

def remove_emojis(text):
    """Supprime tous les emojis du texte apr√®s extraction."""
    return emoji.replace_emoji(text, replace='')



# ============================================
# 2.  CONVERSION DES CHIFFRES DARIJA -> LETTRES
# ============================================

# Mapping des chiffres arabes utilis√©s en Darija vers lettres latines
DARIJA_NUMBER_TO_LETTER = {
    '3': 'a',    # ÿπ (3aslema -> aslema)
    '7': 'h',    # ÿ≠ (7aja -> haja)
    '9': 'k',    # ŸÇ (9ahwa -> kahwa)
    '5': 'kh',   # ÿÆ (5ouya -> khouya)
    '2': 'a',    # ÿ° (2aman -> aman)
    '8': 'gh',   # ÿ∫ (8ali -> ghali) - optionnel
    '6': 't',    # ÿ∑ (6abib -> tabib) - optionnel
}


def convert_darija_numbers_to_letters(text):
    """
    Convertit les chiffres utilis√©s en Darija vers leurs √©quivalents en lettres. 
    
    Exemples:
        - 9ahwa -> kahwa
        - 7aja -> haja
        - 3aslema -> aslema
        - 5ouya -> khouya
        - b7ar -> bhar
        - raw3a -> rawaa
    """
    result = text
    
    # Appliquer les conversions (ordre important:  5 avant les autres car 'kh' = 2 caract√®res)
    # On traite d'abord les patterns sp√©ciaux puis les chiffres simples
    
    # Conversion des chiffres vers lettres
    for number, letter in DARIJA_NUMBER_TO_LETTER.items():
        result = result.replace(number, letter)
    
    return result


def convert_darija_numbers_smart(word):
    """
    Convertit intelligemment les chiffres dans un mot Darija.
    G√®re les cas sp√©ciaux comme les chiffres en d√©but, milieu ou fin de mot.
    
    Exemples:
        - 9wi -> kwi
        - 3aslema -> aslema
        - b7ar -> bhar
        - raw3a -> rawaa
        - 7ala -> hala
        - 5niss -> khniss
    """
    result = word
    
    # Ordre de remplacement important (5 -> kh doit √™tre avant les autres)
    replacements = [
        ('5', 'kh'),   # ÿÆ - doit √™tre en premier car produit 2 caract√®res
        ('9', 'k'),    # ŸÇ
        ('7', 'h'),    # ÿ≠
        ('3', 'a'),    # ÿπ
        ('2', 'a'),    # ÿ°
        ('8', 'gh'),   # ÿ∫
        ('6', 't'),    # ÿ∑
    ]
    
    for number, letter in replacements:
        result = result.replace(number, letter)
    return result


# ============================================
# 3.  NORMALISATION VERS DARIJA TUNISIEN
# ============================================

# Dictionnaire Fran√ßais -> Darija
FRENCH_TO_DARIJA = {
    # Lieux
    'plage': 'bhar',
    'mer': 'bhar',
    'beach': 'bhar',
    'ville': 'mdina',
    'centre': 'west bled',
    'rue': 'chera',
    'quartier': 'houma',
    'maison': 'dar',
    'restaurant': 'resto',
    'caf√©': 'kahwa',
    'h√¥tel': 'hotel',
    'mosqu√©e': 'jemaa',
    'march√©': 'souk',
    'gare': 'mahata',
    'a√©roport': 'matar',
    'h√¥pital': 'sbitar',
    '√©cole': 'madrsa',
    'universit√©': 'fac',
    
    # M√©t√©o / Nature
    'soleil': 'chams',
    'temps': 'jaw',
    'weather': 'takes',
    'chaud': 'skhoun',
    'froid': 'bard',
    'pluie': 'mtar',
    'vent': 'rih',
    'beau': 'mezyen',
    'belle': 'mezyena',
    'magnifique': 'rawa',
    'superbe': 'rawa',
    'joli': 'mezyen',
    'jolie': 'mezyena',
    
    # Sentiments / √âtats
    'bien': 'behi',
    'bon': 'behi',
    'bonne': 'behia',
    'mauvais': 'khayeb',
    'mauvaise': 'khayba',
    'content': 'farhan',
    'contente': 'farhana',
    'heureux': 'farhan',
    'heureuse': 'farhana',
    'triste': 'hzin',
    'fatigu√©': 'taab',
    'fatigu√©e': 'taaba',
    '√©nerv√©': 'metghachech',
    'f√¢ch√©': 'metghachech',
    'super': 'hbel',
    'g√©nial': 'heyel yesser',
    'excellent': 'momtez',
    'parfait': 'heyel',
    'nul': 'khayeb',
    'horrible': 'khayeb yesser',
    'terrible': 'fdhiha',
    
    # Actions
    'manger': 'neklou',
    'boire': 'nochreb',
    'dormir': 'norked',
    'travailler': 'nekhdem',
    'aller': 'nemchi',
    'venir': 'nji',
    'voir': 'nchouf',
    'regarder': 'netfarej',
    'attendre': 'nestana',
    'partir': 'nemchi',
    'rentrer': 'narja',
    'sortir': 'nokhrej',
    
    # Transport
    'voiture': 'karhba',
    'bus': 'kar',
    'taxi': 'taxi',
    'train': 'metro',
    'trafic': 'zahma',
    'embouteillage': 'zahma',
    'circulation': 'zahma',
    'route': 'trik',
    
    # Probl√®mes
    'probl√®me': 'mochkla',
    'panne': 'panne',
    'coupure': 'kass',
    '√©lectricit√©': 'dhaw',
    'internet': 'internet',
    'connexion': 'connexion',
    
    # Temps
    'aujourd\'hui': 'lyoum',
    'demain': 'ghodwa',
    'hier': 'berah',
    'maintenant': 'tawa',
    'toujours': 'dima',
    'jamais': 'abeden',
    'souvent': 'barcha',
    'beaucoup': 'barcha',
    'peu': 'chwaya',
    'tr√®s': 'barcha',
    
    # Personnes
    'gens': 'ness',
    'personnes': 'ness',
    'ami': 'sahbi',
    'amie': 'sahebti',
    'fr√®re': 'khouya',
    's≈ìur': 'okhti',
    'famille': 'ayla',
    'enfants': 'sghar',
    'homme': 'rajel',
    'femme': 'mra',
    'tortue' : 'soulehfet',
    'sauv√©e' : 'monktha',

    'vaccination': 'talkih',
    'gratuite' : 'blech',
    'chats' : 'ktates',
    'chiens' : 'klab',
    'campagne' : 'hemla',

   'inqui√®te' : 'yhazen',
    'autorit√©s' : 'masoulin',
    'tunisiennes' : 'twensa',

    'coupures' : 'kassen',
    '√©lectricit√©' : 'dhaw',
    'zones' : 'manatek',
    'concern√©es' : 'eli ihemha',

     # === Jours de la semaine ===
    'dimanche': 'el had',
    'lundi':   'etnin',
    'mardi':  'ethlatha',
    'mercredi':  'elarbaa',
    'jeudi': 'elkhmis',
    'vendredi': 'ejjomaa',
    'samedi':  'essebt',

    'et' : 'w',
    '√†' : 'fi',
    'ce': 'hadha',
    'cet': 'hadha',
    'cette': 'hedhi',
    'ces': 'hedhom',
 
    'dans': 'fi',
    'parc': 'hadika',
     'rentre': 'yarja',
    'parc': 'hadika',
    'chaque': 'koll',
    'fois': 'marra',

        'je': 'ani',
        'vois': 'nchouf',

        
    # Questions
    'quoi': 'chnoua',
    'comment': 'kifech',
    'pourquoi': 'alech',
    'o√π': 'win',
    'quand': 'waktech',
    'qui': 'chkoun',
    
    # Autres
    'chose': 'haja',
    'jour': 'nhar',
    'nuit': 'lil',
    'matin': 'sbeh',
    'soir': 'achiya',
    'festival': 'festival',
    'match': 'match',
    'foot': 'koura',
    'football': 'koura',
    'tourisme': 'siyeha',
    'touriste': 'siyeha',
    'vacances': 'otla',
     # === Verbes ===
    'prot√©ger': 'nahmiw',
    'proteger': 'nahmiw',
    'prot√®ge': 'nahmi',
    'protegeons': 'nahmiwha',
    
    # === Possessifs ===
    'notre': 'mtaana',
    'nos': 'mtaana',
    'votre': 'mtaakom',
    'vos': 'mtaakom',
    'leur': 'mtaahom',
    'leurs': 'mtaahom',
    'mon': 'mtaai',
    'ma': 'mtaai',
    'mes': 'mtaai',
    'ton': 'mtaak',
    'ta': 'mtaak',
    'tes': 'mtaak',
    'son': 'mtaah',
    'sa': 'mtaah',
    'ses': 'mtaahom',
    
    # === Expressions ===
    "c'est": 'howa',
    'cest': 'howa',
    "c'√©tait": 'ken',
    'cetait': 'ken',
    
    # === Vie / Nature ===
    'vie': 'hayet',
    'la vie': 'el hayet',
    'mort': 'mott',
    'nature': 'tabiaa',
    'environnement': 'biaa',
    'pollution': 'talawoth',
    
    # === Articles ===
    'le': 'el',
    'la':  'el',
    'les': 'el',
    'un': 'wahed',
    'une': 'wahda',
    'des': '',
    
    # === Pronoms ===
    'il': 'houwa',
    'elle': 'hiya',
    'ils': 'houma',
    'elles': 'houma',
    'nous': 'ahna',
    'vous': 'entouma',
    'on': 'ahna',
    
    # === Autres verbes courants ===
    'est': 'howa',
    'sont': 'houma',
    'suis': 'ena',
    'es': 'enti',
    'sommes': 'ahna',
    '√™tes': 'entouma',
    'avoir': 'andou',
    'ai': 'andi',
    'as': 'andek',
    'a': 'andou',
    'avons': 'andna',
    'avez': 'andkom',
    'ont': 'andhom',
    'faire': 'naamel',
    'fait': 'aamel',
    'aimer': 'nheb',
    'aime': 'nheb',
}

# ============================================
# TRANSLITT√âRATION ARABE ‚Üí DARIJA LATIN
# ============================================

# Mapping des lettres arabes vers caract√®res latins (Darija tunisien)
ARABIC_TO_LATIN = {
    # Lettres de base
    'ÿß': 'a',
    'ÿ£': 'a',
    'ÿ•': 'i',
    'ÿ¢': 'a',
    'ÿ®': 'b',
    'ÿ™':  't',
    'ÿ´': 'th',
    'ÿ¨': 'j',
    'ÿ≠': 'h',
    'ÿÆ': 'kh',
    'ÿØ': 'd',
    'ÿ∞': 'dh',
    'ÿ±': 'r',
    'ÿ≤':  'z',
    'ÿ≥': 's',
    'ÿ¥': 'ch',
    'ÿµ': 's',
    'ÿ∂':  'dh',
    'ÿ∑':  't',
    'ÿ∏': 'dh',
    'ÿπ':  'a',
    'ÿ∫': 'gh',
    'ŸÅ': 'f',
    'ŸÇ': 'k',
    'ŸÉ': 'k',
    'ŸÑ': 'l',
    'ŸÖ': 'm',
    'ŸÜ': 'n',
    'Ÿá': 'h',
    'ÿ©': 'a',
    'Ÿà': 'w',
    'Ÿä': 'y',
    'Ÿâ': 'a',
    'ÿ°': '',
    'ÿ¶': 'i',
    'ÿ§': 'ou',
    
    # Voyelles longues / diacritiques (si pr√©sents)
    'Ÿé': 'a',   # Fatha
    'Ÿê':  'i',   # Kasra
    'Ÿè': 'ou',  # Damma
    'Ÿã': 'an',  # Tanwin fath
    'Ÿç': 'in',  # Tanwin kasr
    'Ÿå': 'on',  # Tanwin damm
    'Ÿí': '',    # Sukun
    'Ÿë': '',    # Shadda (on double la lettre pr√©c√©dente)
}
# ============================================
# DICTIONNAIRE ARABE ‚Üí DARIJA LATIN (Fusionn√©)
# ============================================
ARABIC_WORDS_TO_DARIJA_LATIN = {
    # === SENTIMENTS ===
    'ÿ¨ŸÖŸäŸÑ': 'mezyan',
    'ÿ¨ŸÖŸäŸÑÿ©': 'mezyaa',
    'ÿ¨ŸÖŸäŸÑŸá': 'mezyaa', 
    'ÿ±ÿßÿ¶ÿπ': 'heyel',
    'ÿ±ÿßÿ¶ÿπÿ©': 'heyla',
    'ÿ±ÿßÿ¶ÿπŸá': 'heyla',
    'ŸÖŸÖÿ™ÿßÿ≤': 'momtez',
    'ÿ≥Ÿäÿ°': 'khayeb',
    'ÿÆÿßŸäÿ®': 'khayeb',
    'ŸÖÿ¥ŸÉŸÑÿ©': 'mochkla',
    'ŸÖÿ¥ŸÉŸÑŸá': 'mochkla',
    'ŸÖÿ¥ÿßŸÉŸÑ': 'machakel',
    'ÿ≠ÿ≤ŸäŸÜ': 'hzin',
    'ÿ≠ÿ≤ŸäŸÜÿ©':  'hzina',
    'ÿ≠ÿ≤ŸäŸÜŸá': 'hzina',
    'ŸÅÿ±ÿ≠ÿßŸÜ': 'farhan',
    'ŸÅÿ±ÿ≠ÿßŸÜÿ©': 'farhana',
    'ŸÅÿ±ÿ≠ÿßŸÜŸá': 'farhana',
    'ÿ≥ÿπŸäÿØ': 'farhan',
    'ÿ≥ÿπŸäÿØÿ©': 'farhana',
    'ÿ≥ÿπŸäÿØŸá': 'farhana',
    'ÿ™ÿπÿ®': 'taab',
    'ÿ™ÿπÿ®ÿ©':  'taaba',
    'ÿ™ÿπÿ®Ÿá': 'taaba',
    'ÿ™ÿπÿ®ÿßŸÜ': 'taaban',
    'ÿ™ÿπÿ®ÿßŸÜÿ©': 'taabana',
    'ÿ™ÿπÿ®ÿßŸÜŸá': 'taabana',
    # === TEMPS ===
    'ÿßŸÑŸäŸàŸÖ': 'lyoum',
    'ÿ∫ÿØŸàÿ©': 'ghodwa',
    'ÿ∫ÿØÿß': 'ghodwa',
    'ÿßŸÑÿ®ÿßÿ±ÿ≠': 'lbereh',
    'ÿ£ŸÖÿ≥': 'lbereh',
    'ÿ™Ÿàÿß': 'tawa',
    'ÿßŸÑÿ¢ŸÜ': 'tawa',
    'ÿØÿßŸäŸÖÿß': 'dima',
    'ÿØÿßÿ¶ŸÖÿß': 'dima',
    'ÿ®ÿ±ÿ¥ÿß': 'barcha',
    'ŸÉÿ´Ÿäÿ±': 'barcha',
    'Ÿäÿßÿ≥ÿ±': 'yesser',
    'ÿ¥ŸàŸäÿ©': 'chwaya',
    'ŸÇŸÑŸäŸÑ': 'chwaya',
    'ŸäŸàŸÖ': 'nhar',
    'ŸÑŸäŸÑ': 'lil',
    'ÿµÿ®ÿßÿ≠': 'sbeh',
    'ŸÖÿ≥ÿßÿ°': 'achiya',
    
    # === LIEUX ===
    'ÿßŸÑÿ®ÿ≠ÿ±': 'bhar',
    'ÿßŸÑÿ¥ÿßÿ∑ÿ¶': 'chatt',
    'ÿßŸÑŸÖÿØŸäŸÜÿ©': 'mdina',
    'ÿßŸÑÿ®ŸÑÿßÿØ': 'bled',
    'ÿßŸÑÿ≠ŸàŸÖÿ©': 'houma',
    'ÿßŸÑÿØÿßÿ±': 'dar',
    'ÿßŸÑŸÖŸÜÿ≤ŸÑ': 'dar',
    'ÿßŸÑÿ≥ŸàŸÇ': 'souk',
    'ÿßŸÑÿ¨ÿßŸÖÿπ': 'jemaa',
    'ÿßŸÑŸÖÿ∑ÿßÿ±': 'matar',
    'ÿßŸÑŸÖÿ≠ÿ∑ÿ©': 'mahata',
    'ÿßŸÑÿ≥ÿ®Ÿäÿ∑ÿßÿ±': 'sbitar',
    'ÿßŸÑŸÖÿ≥ÿ™ÿ¥ŸÅŸâ': 'sbitar',
    'ÿßŸÑŸÖÿØÿ±ÿ≥ÿ©': 'madrsa',
    'ÿßŸÑÿ¨ÿßŸÖÿπÿ©': 'fac',
    'ÿßŸÑŸÉŸàÿ±ŸÜŸäÿ¥': 'corniche',
    'ÿßŸÑŸÖŸÑÿπÿ®': 'stade',
    'ÿßŸÑÿ±ÿ®ÿßÿ∑': 'ribat',
    'ŸÇÿµÿ±': 'ksar',
    'ÿßŸÑŸÖÿ±ŸÉÿ®': 'morakeb',
    'ÿßŸÑÿ∑ÿ±ŸäŸÇ': 'trik',
    'ÿßŸÑŸÖŸÜÿ≥ÿ™Ÿäÿ±': 'mestir',
    'ÿßŸÑŸÖÿ≥ÿ™Ÿäÿ±': 'mestir',
    'ŸÖŸÜÿ≥ÿ™Ÿäÿ±': 'mestir',
    'ÿßŸÑŸÖÿ∑ÿπŸÖ': 'resto',
    'ÿßŸÑŸÖŸÇŸáŸâ': 'kahwa',
    
    # === PERSONNES ===
    'ÿßŸÑŸÜÿßÿ≥': 'ness',
    'ŸÜÿßÿ≥': 'ness',
    'ÿµÿßÿ≠ÿ®Ÿä': 'sahbi',
    'ÿµÿØŸäŸÇ': 'sahbi',
    'ÿµÿØŸäŸÇÿ©': 'sahebti',
    'ÿÆŸàŸäÿß': 'khouya',
    'ÿ£ÿÆ': 'khou',
    'ÿ£ÿÆÿ™Ÿä': 'okhti',
    'ÿ£ÿÆÿ™': 'okht',
    'ÿßŸÑÿπÿßŸäŸÑÿ©': 'ayla',
    'ÿπÿßÿ¶ŸÑÿ©': 'ayla',
    'ÿßŸÑÿµÿ∫ÿßÿ±': 'sghar',
    'ÿ£ÿ∑ŸÅÿßŸÑ': 'sghar',
    'ÿ±ÿßÿ¨ŸÑ': 'rajel',
    'ÿ±ÿ¨ŸÑ': 'rajel',
    'ŸÖÿ±ÿß': 'mra',
    'ÿßŸÖÿ±ÿ£ÿ©': 'mra',
    'ÿ£ÿ®': 'baba',
    'ÿ£ŸÖ': 'ommi',
    'ÿßÿ®ŸÜ': 'wled',
    'ÿßÿ®ŸÜÿ©':  'bent',
    'ÿ¨ÿØ': 'jed',
    'ÿ¨ÿØÿ©': 'jeda',
    
    # === TRANSPORT ===
    'ÿßŸÑŸÉÿ±Ÿáÿ®ÿ©': 'karhba',
    'ŸÉÿ±Ÿáÿ®ÿ©': 'karhba',
    'ÿßŸÑÿ≥Ÿäÿßÿ±ÿ©': 'karhba',
    'ÿßŸÑŸÉÿßÿ±': 'kar',
    'ÿßŸÑÿ≠ÿßŸÅŸÑÿ©': 'kar',
    'ÿßŸÑÿ∑ÿßŸÉÿ≥Ÿä': 'taxi',
    'ÿßŸÑŸÖŸäÿ™ÿ±Ÿà': 'metro',
    'ÿßŸÑŸÇÿ∑ÿßÿ±': 'metro',
    'ÿßŸÑÿ∑ÿßÿ¶ÿ±ÿ©': 'tayara',
    'ÿ≤ÿ≠ŸÖÿ©': 'zahma',
    'ÿßŸÑÿ≤ÿ≠ŸÖÿ©': 'zahma',
    
    # === M√âT√âO ===
    'ÿßŸÑÿ¨Ÿà': 'jaw',
    'ÿ¨Ÿà': 'jaw',
    'ÿßŸÑÿ∑ŸÇÿ≥': 'jaw',
    'ÿßŸÑÿ¥ŸÖÿ≥': 'chams',
    'ÿ¥ŸÖÿ≥': 'chams',
    'ÿ≥ÿÆŸàŸÜ': 'skhoun',
    'ÿ≠ÿßÿ±': 'skhoun',
    'ÿ®ÿ±ÿØ': 'bard',
    'ÿ®ÿßÿ±ÿØ': 'bard',
    'ŸÖÿ∑ÿ±': 'mtar',
    'ÿ±Ÿäÿ≠': 'rih',
    
    # === ACTIONS ===
    'ŸÜÿßŸÉŸÑ': 'nekel',
    'ÿ£ŸÉŸÑ': 'mekla',
    'ŸÜÿ¥ÿ±ÿ®': 'nochreb',
    'ÿ¥ÿ±ÿ®':  'chrab',
    'ŸÜÿ±ŸÇÿØ': 'norked',
    'ŸÜŸàŸÖ':  'rked',
    'ŸÜÿÆÿØŸÖ': 'nekhdem',
    'ÿπŸÖŸÑ': 'khedma',
    'ÿßŸÑÿπŸÖŸÑ': 'khedma',
    'ŸÜŸÖÿ¥Ÿä': 'nemchi',
    'ŸÜÿ¨Ÿä': 'nji',
    'ŸÜÿ¥ŸàŸÅ': 'nchouf',
    'ŸÜÿ™ŸÅÿ±ÿ¨': 'netfarej',
    'ŸÜÿ≥ÿ™ŸÜŸâ': 'nestana',
    'ŸÜÿ±ÿ¨ÿπ': 'narja',
    'ŸÜÿÆÿ±ÿ¨': 'nokhrej',
    
    # === QUESTIONS ===
    'ÿ¥ŸÜŸàÿ©': 'chnoua',
    'ŸÖÿßÿ∞ÿß': 'chnoua',
    'ŸÉŸäŸÅÿßÿ¥': 'kifech',
    'ŸÉŸäŸÅ': 'kifech',
    'ÿπŸÑÿßÿ¥': 'alech',
    'ŸÑŸÖÿßÿ∞ÿß': 'alech',
    'ŸàŸäŸÜ': 'win',
    'ÿ£ŸäŸÜ': 'win',
    'ŸàŸÇÿ™ÿßÿ¥': 'wakteh',
    'ŸÖÿ™Ÿâ': 'wakteh',
    'ÿ¥ŸÉŸàŸÜ': 'chkoun',
    'ŸÖŸÜ': 'men',
    'ÿ¥Ÿäÿ°': 'chy',
    'Ÿàÿ≤ŸäŸÜ': 'w mezyan',
    'ÿßŸÑÿ™ÿ£ÿÆŸäÿ±': 'tawkhir',
    'ÿ™ÿ∞ŸÖŸëŸàÿß': 'tdhamrou',
    'ŸÅŸàŸÑŸÉŸÑŸàÿ±': 'folklore',
    # === CHIFFRES ===
    'Ÿàÿßÿ≠ÿØ': 'wahed',
    'ÿßÿ´ŸÜÿßŸÜ':  'zouz',
    'ÿ´ŸÑÿßÿ´ÿ©': 'thletha',
    'ÿ£ÿ±ÿ®ÿπÿ©': 'arbaa',
    'ÿÆŸÖÿ≥ÿ©': 'khamsa',
    'ÿ≥ÿ™ÿ©': 'setta',
    'ÿ≥ÿ®ÿπÿ©': 'sebaa',
    'ÿ´ŸÖÿßŸÜŸäÿ©': 'thmenia',
    'ÿ™ÿ≥ÿπÿ©': 'tesaa',
    'ÿπÿ¥ÿ±ÿ©': 'achra',
    
    # === MAISON & OBJETS ===
    'ÿ∫ÿ±ŸÅÿ©': 'bit',
    'ÿ∫ÿ±ŸÅŸá': 'bit',
    'ŸÖÿ∑ÿ®ÿÆ': 'koujina',
    'ÿ≠ŸÖÿßŸÖ': 'hamem',
    'ÿ®ÿßÿ®': 'beb',
    'ŸÜÿßŸÅÿ∞ÿ©': 'chobek',
    'ÿ≥ÿ±Ÿäÿ±': 'srir',
    'ŸÉÿ±ÿ≥Ÿä': 'korsi',
    'ÿ∑ÿßŸàŸÑÿ©': 'tawle',
    'ŸÖŸÅÿ™ÿßÿ≠': 'mefteh',
    'ŸÜÿßÿ±':  'nar',
    'ÿ´ŸÑÿßÿ¨ÿ©': 'frigidaire',
    
    # === NOURRITURE ===
    'ÿÆÿ®ÿ≤': 'khobz',
    'ŸÖÿßÿ°':  'ma',
    'ÿ¥ÿßŸä': 'tey',
    'ŸÇŸáŸàÿ©': 'kahwa',
    'ŸÑÿ≠ŸÖ': 'lham',
    'ÿØÿ¨ÿßÿ¨': 'djej',
    'ÿ≥ŸÖŸÉ':  'hout',
    'ŸÖŸÑÿ≠': 'melh',
    'ÿ≥ŸÉÿ±':  'sokkar',
    'ŸÅÿßŸÉŸáÿ©': 'ghalla',
    'ÿ™ŸÅÿßÿ≠': 'toffeh',
    'ÿ®ÿ±ÿ™ŸÇÿßŸÑ': 'bordgen',
    'ŸÖŸàÿ≤': 'banane',
       # === MOIS ===
    'ŸäŸÜÿßŸäÿ±': 'janvier',
    'ÿ¨ÿßŸÜŸÅŸä': 'janvier',
    'ŸÅÿ®ÿ±ÿßŸäÿ±':  'fevrier',
    'ŸÅŸäŸÅÿ±Ÿä': 'fevrier',
    'ŸÖÿßÿ±ÿ≥':  'mars',
    'ÿ£ÿ®ÿ±ŸäŸÑ': 'avril',
    'ÿßŸÅÿ±ŸäŸÑ': 'avril',
    'ŸÖÿßŸä': 'mai',
    'ŸÖÿßŸäŸà': 'mai',
    'ŸäŸàŸÜŸäŸà': 'juin',
    'ÿ¨ŸàÿßŸÜ':  'juin',
    'ŸäŸàŸÑŸäŸà': 'juillet',
    'ÿ¨ŸàŸäŸÑŸäÿ©': 'juillet',
    'ÿ£ÿ∫ÿ≥ÿ∑ÿ≥': 'aout',
    'ÿßŸàÿ™': 'aout',
    'ÿ≥ÿ®ÿ™ŸÖÿ®ÿ±': 'septembre',
    'ÿ£ŸÉÿ™Ÿàÿ®ÿ±': 'octobre',
    'ÿßŸÉÿ™Ÿàÿ®ÿ±': 'octobre',
    'ŸÜŸàŸÅŸÖÿ®ÿ±': 'novembre',
    'ÿØŸäÿ≥ŸÖÿ®ÿ±': 'decembre',
    # === TECHNOLOGIE ===
    'ÿ≠ÿßÿ≥Ÿàÿ®': 'pc',
    'Ÿáÿßÿ™ŸÅ': 'portable',
    'ÿ•ŸÜÿ™ÿ±ŸÜÿ™': 'internet',
    'ÿµŸàÿ±ÿ©': 'taswira',
    
    # === √âV√âNEMENTS ===
    'ÿ≠ŸÅŸÑÿ©': 'hafla',
    'ÿ≠ŸÅŸÑŸá': 'hafla',
    'ÿπÿ±ÿ∂': 'ardh',
    'ŸÖÿ®ÿßÿ±ÿßÿ©': 'match',
    'ŸÖÿ®ÿßÿ±ÿßŸá': 'match',
    'ŸÉÿ±ÿ©': 'koura',
    'ŸÉÿ±Ÿá':  'koura',
    'ŸÅŸäŸÑŸÖ': 'film',
    'ŸÖÿ≥ÿ±ÿ≠': 'masrah',
    'ŸÖŸàÿ≥ŸäŸÇŸâ': 'mousika',

    'ŸÅŸÜ': 'fann',
    'ÿ´ŸÇÿßŸÅÿ©': 'thakafa',
    'ÿ≥Ÿäÿßÿ≠ÿ©': 'siyeha',
    'ÿπÿ∑ŸÑÿ©': 'otla',
    'ŸÖŸáÿ±ÿ¨ÿßŸÜ': 'mahrejen',
    'ÿ™ŸÜÿ∏ŸäŸÖ': 'tandhim',
    'ÿ™ÿ£ÿÆŸäÿ±': 'takhir',
    
    # === EXPRESSIONS ===
    'ŸàÿßŸÑŸÑŸá': 'wallah',
    'ŸäÿπŸÜŸä': 'yaani',
    'ÿ®ÿ±ŸÉ': 'bark',
    'ÿ≤ÿπŸÖÿ©': 'zaama',
    'ÿ®ÿßŸáŸä': 'behi',
    'ÿµÿ≠ÿ©': 'saha',
    'ÿπÿ≥ŸÑÿßŸÖÿ©': 'aslema',
    'ÿßŸÑÿÆŸäÿ±': 'khir',
    'ŸÑŸäŸÑÿ©': 'lila',
    'ŸÖÿ®ÿ±ŸàŸÉ': 'mabrouk',
    
    # === MOTS SP√âCIFIQUES AUX DONN√âES ===
    'ÿßŸÑÿØŸÜŸäÿß': 'denya',
    'ÿ≠ŸÑŸàÿ©': 'hlowa',
    'ÿ≠ŸÑŸàŸá': 'hlowa',    
    'ÿ≠ŸÑŸà': 'hlou',
    'ŸÖÿπÿ®Ÿä': 'maabi',
    'ŸÖÿπÿ®ŸëŸä': 'maabi',
    'ÿßŸÑÿßŸÅÿ™ÿ™ÿßÿ≠': 'eftiteh',
    'ÿßŸÑŸÉÿ®Ÿäÿ±': 'kbir',
    'ŸÉÿ®Ÿäÿ±': 'kbir',
    'ŸÖÿ™ÿßÿπ': 'mtaa',
    'ÿµÿ±ÿßÿ≠ÿ©': 'sraha',
    'ÿßŸÑÿ™ŸàŸÇÿπÿßÿ™': 'tawakkoaat',
    'ÿ™ÿ∞ŸÉŸäÿ±': 'tadhkir',
    'ÿπŸÜÿØ': 'and',
    'ÿπŸÑŸâ': 'ala',
    'ÿßŸÑÿ≥ÿßÿπÿ©': 'saa',
    'ÿπÿßŸÖÿ±': 'amer',
    'ŸÇŸàŸäÿ©': 'kwiya',
    'ŸÇŸàŸäŸá':  'kwiya',
    'ŸÇŸàŸä': 'kwi',
    'ÿ™ÿ¥ÿ¨ÿπ': 'tchajaa',
    'ÿ®ŸÉÿ±Ÿä': 'bekri',
    'ÿ¨ÿØŸäÿØÿ©': 'jdida',
    'ÿ¨ÿØŸäÿØŸá':  'jdida',
    'ÿ¨ÿØŸäÿØ': 'jdid',
    'ÿßŸÑÿ•ÿ∂ÿßÿ°ÿ©': 'dhaw',
    'ÿßŸÑŸÖŸÇÿßÿ®ŸÑÿ©': 'match',
    'ÿ™ÿπÿ∑ŸÑÿ™': 'taatlet',
    'ÿßŸÑÿ∑ÿ®ÿÆ': 'tabkh',
    'ÿßŸÑŸÖÿ±ŸÉÿ≤Ÿä': 'markazi',
    'ÿÆÿ∂ÿ±': 'khodhra',
    'ÿ∑ÿßÿ≤ÿ¨ÿ©': 'tazja',
    'ÿ∑ÿßÿ≤ÿ¨Ÿá': 'tazja',
    'ÿ∑ŸÖÿßÿ∑ŸÖ': 'tmatem',
    'ÿ®ŸÜŸäŸÜÿ©': 'bnina',
    'ÿ®ŸÜŸäŸÜŸá': 'bnina',
    'ÿ®ŸÜŸäŸÜ': 'bnin',
    'ÿπÿ±Ÿàÿ∂': 'oroudh',
    'ÿßŸÑÿ®Ÿáÿ¨ÿ©': 'behja',
    'ÿßŸÑÿ¥ÿßÿ±ÿπ': 'cheraa',
    'ŸÇÿØÿßŸÖ': 'koddem',
    'ÿßŸÑÿ™ÿµÿßŸàÿ±': 'tsawer',
    'ÿ≥Ÿäÿßÿ≠Ÿä': 'siyehi',
    'ŸÖŸÜÿ∏ŸÖ': 'mnadhem',
    'ŸÖÿ≤ŸäÿßŸÜ': 'mezyen',
    'ÿßŸÑÿµŸàÿ™': 'sot',
    'ÿßŸÑŸÇÿßÿπÿ©': 'salla',
    'ŸÖÿ≤ÿπÿ¨': 'ikalek',
    'ÿ¨ŸÖÿπÿ©': 'jomaa',
    'ÿ´ŸÇÿßŸÅŸäÿ©': 'thakafiya',
    'ÿ´ŸÇÿßŸÅŸäŸá': 'thakafiya',
    'ŸÖÿπÿ±ÿ∂': 'maaredh',
    'ŸÉÿ™ÿ®': 'kotob',
    'ÿµÿ∫Ÿäÿ±': 'sghir',
    'ÿµÿ∫Ÿäÿ±ÿ©': 'sghira',
    'ÿµÿ∫Ÿäÿ±Ÿá': 'sghira',
    'ŸÑŸÑŸÉŸàÿ±ŸÜŸäÿ¥': 'lel_corniche',
    'ÿßŸÑÿ∫ÿ±Ÿàÿ®': 'ghroub',
    'ŸáÿßÿØŸä': 'hedi',
    'ÿ≤ŸäŸÜ': 'zin',
    'ÿßŸÑŸÖÿ≥ÿ±ÿ≠Ÿä': 'masrahi',
    'ÿ∂ÿπŸäŸÅ': 'dhaif',
    'ÿ¥ŸàŸä': 'chwi',
    'ÿßŸÑŸÖŸÜÿ∑ŸÇÿ©': 'mantka',
    'ÿ∑ÿ±ŸÇÿßÿ™': 'torkaat',
    'ÿµŸäÿßŸÜÿ©': 'siyana',
    'ÿßŸÑŸÖÿ±Ÿàÿ±': 'morour',
    'ÿ£ÿÆÿ®ÿßÿ±': 'akhbar',
    'ÿ≥ÿ±Ÿäÿπÿ©': 'sriaa',
    'ÿ≥ÿ±ŸäÿπŸá': 'sriaa',
    'ŸÜÿØŸàÿ©': 'nadwa',
    'ŸÜÿØŸàŸá': 'nadwa',
    'ÿßŸÑÿπŸÑŸàŸÖ': 'oloum',
    'ŸÖÿ¥ÿßÿ±Ÿäÿπ': 'macharia',
    'ÿ¨ÿßŸÖÿπÿ©': 'jemaa',
    'ÿµŸàÿ±ÿ©': 'soura',
    'ÿµŸàÿ±Ÿá': 'soura',
    'ÿßŸÑŸÖÿ≥ÿ™ŸàŸâ': 'mostwa',
    'ŸÉŸÑŸäÿ©': 'koliya',
    'ŸÜŸÇÿµ': 'noks',
    'ÿßŸÑÿ∑ŸÑÿ®ÿ©': 'talaba',
    'ÿ£ŸäÿßŸÖ': 'ayem',
    'ÿ≥ŸäŸÜŸÖÿß': 'cinema',
    'ÿ™ÿ≠ÿ™': 'taht',
    'ÿßŸÑŸÜÿ¨ŸàŸÖ': 'njoum',
    'ÿßŸÑÿ≥Ÿáÿ±ÿ©': 'sahra',
    'ÿ∑ŸàŸäŸÑÿ©': 'twila',
    'ÿ∑ŸàŸäŸÑŸá':  'twila',
    'ÿ∑ŸàŸäŸÑ': 'twil',
    'ÿßŸÑŸÅÿ±ŸÇÿ©': 'ferka',
    'ÿßŸÑŸÖŸàÿØÿ±ŸÜ': 'moderna',
    'ŸÑŸÑÿßÿπÿ®ŸäŸÜ': 'lel_laabin',
    'ÿ£ŸàŸÑ': 'awel',
    'ÿ±ÿ≥ŸÖŸä': 'rasmi',
    'ÿ≠ÿ±ŸÉÿ©': 'haraka',
    'ÿ≠ÿ±ŸÉŸá': 'haraka', 
    'ÿ±Ÿäÿßÿ∂Ÿäÿ©': 'riyadhiya',
    'ÿßŸÑÿ¥ÿ®ÿßÿ®': 'chabeb',
    'ÿ≠ŸàŸÑ': 'hawel',
    'ÿ™ÿßÿ±ŸäÿÆ': 'tarikh',
    'ÿ¢ÿÆÿ±': 'akher',
    'ÿßŸÑÿπŸÑŸÖŸäÿ©': 'ilmiya',
    'ÿπŸÑŸÖŸäÿ©': 'ilmiya',
    'ÿπŸÑŸÖŸäŸá': 'ilmiya',
    'ŸÖŸàÿπÿØŸÜÿß': 'mawidna',
    'ÿ¨ŸÖŸáŸàÿ±': 'jomhour',
    'ÿßŸÑÿ≠ÿ®Ÿäÿ®': 'hbib',
    'ŸÜÿ∫ŸÜŸä': 'nghanni',
    'ÿßŸÑŸÖŸàÿ≥ŸÖ': 'mawsem',
    'ÿ™ÿÆŸÅŸäÿ∂': 'takhfidh',
    'ŸÅŸÜÿØŸÇ': 'fondok',
    'ŸÖŸàŸÇÿπ': 'mawkaa',
    'ÿÆÿØŸÖÿßÿ™': 'khadamet',
    'ŸÖÿ≥ÿßÿ®ŸÇÿ©': 'mosabka',
    'ŸÖÿ≥ÿßÿ®ŸÇŸá': 'mosabka',
    'ÿ¨ŸÖÿßŸÑ': 'jamel',
    'ŸÅŸàÿ¨': 'fawj',
    'ÿ±Ÿäÿßÿ∂Ÿäÿ©': 'riyadhiya',
    'ÿ±Ÿäÿßÿ∂ŸäŸá': 'riyadhiya',
    'ÿßŸÑÿ™ŸàŸÜÿ≥Ÿäÿ©': 'tounsiya',
    'ÿßŸÑÿ™ŸàŸÜÿ≥ŸäŸá': 'tounsiya',
    'ÿ¨Ÿáÿ©': 'jiha',
    'ŸÇŸÑÿ®': 'kalb',
    'ÿ£ÿ¨Ÿàÿßÿ°': 'ajwaa',
    'ÿßŸÑÿπŸäÿØ': 'eid',
    'ŸÉÿ®ÿßÿ±': 'kbar',
    'ÿ™ŸÅÿßÿµŸäŸÑ': 'tafasil',
    'ŸÜÿßÿ¨ÿ≠': 'najeh',
    'ÿßŸÑŸÖÿ≥ÿ§ŸàŸÑ': 'masoul',
    'ÿßŸÑŸÖÿ≥ÿ°ŸàŸÑ': 'masoul',
    'ÿßŸÑŸÜŸÇŸÑ': 'nakl',
    'ŸÖÿπÿßŸÜÿßÿ©': 'mouanet',
    'ÿßŸÑŸÖÿ≥ÿßŸÅÿ±ŸäŸÜ': 'msafrin',
    'ÿ∫Ÿäÿßÿ®': 'ghyab',
    'ÿ±ÿ≠ŸÑÿßÿ™': 'rahlat',
    'ŸÖŸàÿ¥': 'mouch',
    'ŸÇÿØ': 'ked',
    'ŸÅŸä': 'fi',
    'Ÿà': 'w',
    'ŸÖÿß': 'ma',
    'ŸáŸä': 'hiya',
    'ŸáŸà': 'houwa',
    'ŸÉÿßŸÜ': 'ken',
    'ŸÉÿßŸÜÿ™': 'kenet',
    'ŸÅŸäŸá': 'fih',
    'ŸÅŸäŸáÿß': 'fiha',
    'ÿπŸÑŸäŸá': 'alih',
    'ÿπŸÑŸäŸáÿß':  'aliha',
    'ŸÖŸÜŸá': 'menou',
    'ŸÖŸÜŸáÿß': 'menha',
    'ÿ•ŸÑŸâ': 'lel',
    'ŸÖÿπ': 'maa',
    'ÿ®ÿπÿØ': 'baad',
    'ŸÇÿ®ŸÑ': 'kabl',
    'ÿ®ŸäŸÜ': 'bin',
    'ŸÉŸÑ': 'kol',
    'ÿ®ÿπÿ∂': 'baadh',
    'Ÿáÿ∞ÿß': 'hadha',
    'Ÿáÿ∞Ÿá': 'hedhi',
    'ÿ∞ŸÑŸÉ': 'dhalik',
    'ŸáŸÜÿß': 'hne',
    'ŸáŸÜÿßŸÉ':  'ghadika',
    'ÿßŸÑÿ∞Ÿä': 'eli',
    'ÿßŸÑÿ™Ÿä': 'eli',
    'ÿßŸÑŸÑŸä': 'eli',
    'Ÿà': 'w',
    'ŸÖŸàŸÉŸÜŸäŸÜ': 'moknin',
    'ÿ®ÿ≥ÿ®ÿ®': 'bisebab',
}

# Dictionnaire Translitt√©ration Darija -> Darija normalis√©
DARIJA_NORMALIZATION = {
    # Variantes orthographiques courantes
    'ta7et': 'tahet',
    '7ala': 'hala',
    '7lila': 'hlila',
    '3alekher': 'alekher',
    '7ata': 'hata',
    'wa5ret': 'wakhret',
    '9a3din': 'kadin',
    'na7kiw': 'nahkiw',
    '3la': 'ala',
    'm3abba': 'maaba',
    '3ib': 'eib',
    '3malet': 'amelt',
    '9ass': 'kass',
    'ye5y': 'yekhy',
    '3alya': 'alya',
    '9wi': 'kwi',
    'tet3eda': 'tetada',
    '3aslema': 'aslema',

    'raw3a': 'rawaa',
    'raw3aa': 'rawaa',
    'raw3a': 'rawaa',
    'rou3a': 'rawaa',
    'barcha': 'barcha',
    'barchaa': 'barcha',
    'bercha': 'barcha',
    'barsha': 'barcha',
    'barshaa': 'barcha',
    '7ajet': 'hajet',
    '7weyej': 'hajet',
    '7aja': 'haja',
    '5ouya': 'khouya',
    '5oya': 'khouya',
    'kifech': 'kifech',
    'kifeh': 'kifech',
    'kifek': 'kifech',
    'chneya': 'chneya',
    'chnoua': 'chnoua',
    'chnowa': 'chnowa',
    'chnya': 'chnya',
    'wallahi': 'wallah',
    'walahi': 'wallah',
    'wlh': 'wallah',
    'wlhi' : 'wallah',
    '9ahwa': 'kahwa',
    '9ahaoua': 'kahwa',
    'm3a': 'maa',
    'b7ar': 'bhar',
    'ba7ar': 'bhar',
    'thama': 'fama',
    'thamma': 'fama',
    'famma': 'fama',
    'jaw': 'jaw',
    'jow': 'jaw',
    'ness': 'ness',
    'nas': 'ness',
    'naas': 'ness',
    'sa7': 'saha',
    'sa7a': 'saha',
    'mashi': 'machi',
    'ya3ni': 'yaani',
    'choufe': 'chouf',
    'shouf': 'chouf',
    'ra7': 'mcha',
    'msha': 'mcha',
    'mechi': 'mcha',
    'elyoum': 'lyoum',
    'lyom': 'lyoum',
    'leyouma': 'lyoum',
    # Lieux Monastir
    'monastir': 'mestir',
    'elmonstir': 'mestir',
    'el monastir': 'mestir',
    '5niss': 'khniss',
    'khnis': 'khniss',
    'usmonastir': 'us mestir',
    'steg': 'steg',
}
# Mots √† garder tels quels (noms propres, etc.)
KEEP_AS_IS = {'steg', 'us', 'mestir', 'facebook', 'instagram', 'twitter'}

# ============================================
# PROTECTION DES NOMBRES ET FORMATS SP√âCIAUX
# ============================================

import re

# Variable globale pour stocker les patterns prot√©g√©s
_protected_values = {}
_protection_counter = 0

# Mois en arabe et fran√ßais pour la protection
MONTHS_ARABIC = [
    'ŸäŸÜÿßŸäÿ±', 'ÿ¨ÿßŸÜŸÅŸä', 'ÿ¨ÿßŸÜŸÅŸäŸäŸá',     # Janvier
    'ŸÅÿ®ÿ±ÿßŸäÿ±', 'ŸÅŸäŸÅÿ±Ÿä',               # F√©vrier
    'ŸÖÿßÿ±ÿ≥',                          # Mars
    'ÿ£ÿ®ÿ±ŸäŸÑ', 'ÿßŸÅÿ±ŸäŸÑ',                # Avril
    'ŸÖÿßŸä', 'ŸÖÿßŸäŸà',                   # Mai
    'ŸäŸàŸÜŸäŸà', 'ÿ¨ŸàÿßŸÜ',                 # Juin
    'ŸäŸàŸÑŸäŸà', 'ÿ¨ŸàŸäŸÑŸäÿ©',               # Juillet
    'ÿ£ÿ∫ÿ≥ÿ∑ÿ≥', 'ÿßŸàÿ™',                  # Ao√ªt
    'ÿ≥ÿ®ÿ™ŸÖÿ®ÿ±', 'ÿ≥ÿ®ÿ™ÿßŸÖÿ®ÿ±',             # Septembre
    'ÿ£ŸÉÿ™Ÿàÿ®ÿ±', 'ÿßŸÉÿ™Ÿàÿ®ÿ±',              # Octobre
    'ŸÜŸàŸÅŸÖÿ®ÿ±', 'ŸÜŸàŸÅÿßŸÖÿ®ÿ±',             # Novembre
    'ÿØŸäÿ≥ŸÖÿ®ÿ±', 'ÿØŸäÿ≥ÿßŸÖÿ®ÿ±',             # D√©cembre
]

MONTHS_FRENCH = [
    'janvier', 'fevrier', 'f√©vrier', 'mars', 'avril', 'mai', 'juin',
    'juillet', 'aout', 'ao√ªt', 'septembre', 'octobre', 'novembre', 'decembre', 'd√©cembre'
]

def extract_protected_patterns(text):
    """
    Extrait et prot√®ge les patterns sp√©ciaux (temps, dates, nombres).
    """
    global _protected_values, _protection_counter
    _protected_values = {}
    _protection_counter = 0
    
    result_text = text
    
   # 1. Prot√©ger les PLAGES de dates avec mois en arabe (ex: 2 Ÿà3 ŸÖÿßŸä 2025, 30 ÿ£ŸÉÿ™Ÿàÿ®ÿ± ŸÑŸÄ1 ŸÜŸàŸÅŸÖÿ®ÿ±)
    for month in MONTHS_ARABIC:
        # Pattern:  nombre + Ÿà/- + nombre + mois + ann√©e optionnelle
        # Ex: 2 Ÿà3 ŸÖÿßŸä 2025 ou 2-3 ŸÖÿßŸä 2025
        pattern = rf'\b(\d{{1,2}})\s*[ŸàŸà\-]\s*(\d{{1,2}})\s+{month}(\s+\d{{4}})?\b'
        matches = list(re.finditer(pattern, result_text))
        for match in reversed(matches):
            original_value = match.group()
            placeholder = f"PROT{_protection_counter}PROT"
            _protected_values[placeholder] = original_value
            _protected_values[placeholder.lower()] = original_value
            result_text = result_text[: match.start()] + placeholder + result_text[match.end():]
            _protection_counter += 1
    
    # 2. Prot√©ger les dates simples avec mois en arabe (ex: 30 ÿ£ŸÉÿ™Ÿàÿ®ÿ±, 1 ŸÜŸàŸÅŸÖÿ®ÿ±)
    for month in MONTHS_ARABIC:
        # Pattern: nombre + espace + mois + ann√©e optionnelle
        pattern = rf'\b(\d{{1,2}})\s+{month}(\s+\d{{4}})?\b'
        matches = list(re.finditer(pattern, result_text))
        for match in reversed(matches):
            # V√©rifier que ce n'est pas d√©j√† prot√©g√©
            if 'PROT' in result_text[max(0, match.start()-10):match.end()+10]:
                continue
            original_value = match.group()
            placeholder = f"PROT{_protection_counter}PROT"
            _protected_values[placeholder] = original_value
            _protected_values[placeholder.lower()] = original_value
            result_text = result_text[:match.start()] + placeholder + result_text[match.end():]
            _protection_counter += 1
    
      # 3. Prot√©ger les plages de dates avec mois en fran√ßais
    for month in MONTHS_FRENCH:
        pattern = rf'\b(\d{{1,2}})\s*[et\-ŸàŸà]\s*(\d{{1,2}})\s+{month}(\s+\d{{4}})?\b'
        matches = list(re.finditer(pattern, result_text, re.IGNORECASE))
        for match in reversed(matches):
            original_value = match.group()
            placeholder = f"PROT{_protection_counter}PROT"
            _protected_values[placeholder] = original_value
            _protected_values[placeholder.lower()] = original_value
            result_text = result_text[: match.start()] + placeholder + result_text[match.end():]
            _protection_counter += 1
    
    # 4. Prot√©ger les dates simples avec mois en fran√ßais
    for month in MONTHS_FRENCH:
        pattern = rf'\b(\d{{1,2}})\s+{month}(\s+\d{{4}})?\b'
        matches = list(re.finditer(pattern, result_text, re.IGNORECASE))
        for match in reversed(matches):
            if 'PROT' in result_text[max(0, match.start()-10):match.end()+10]:
                continue
            original_value = match.group()
            placeholder = f"PROT{_protection_counter}PROT"
            _protected_values[placeholder] = original_value
            _protected_values[placeholder.lower()] = original_value
            result_text = result_text[:match.start()] + placeholder + result_text[match.end():]
            _protection_counter += 1
    
    # 5. Prot√©ger les plages de dates entre deux mois (ex: 30 ÿ£ŸÉÿ™Ÿàÿ®ÿ± ŸÑŸÄ1 ŸÜŸàŸÅŸÖÿ®ÿ±)
    for month1 in MONTHS_ARABIC: 
        for month2 in MONTHS_ARABIC:
            pattern = rf'\b(\d{{1,2}})\s+{month1}\s+[ŸÑŸêŸÄŸÑ]+\s*(\d{{1,2}})\s+{month2}\b'
            matches = list(re. finditer(pattern, result_text))
            for match in reversed(matches):
                if 'PROT' in result_text[max(0, match.start()-10):match.end()+10]:
                    continue
                original_value = match. group()
                placeholder = f"PROT{_protection_counter}PROT"
                _protected_values[placeholder] = original_value
                _protected_values[placeholder.lower()] = original_value
                result_text = result_text[:match.start()] + placeholder + result_text[match.end():]
                _protection_counter += 1
    
    # 3. Patterns num√©riques classiques
    patterns = [
        (r'\b\d{1,2}:\d{2}\b', 'time'),              # 18:30, 9:00
        (r'\b\d{1,2}h\d{2}\b', 'time'),              # 14h30
        (r'\b\d{1,2}[/\-\. ]\d{1,2}[/\-\. ]\d{2,4}\b', 'date'),  # 25/12/2024
        (r'\b\d{1,2}[/\-\.]\d{1,2}\b', 'date'),      # 25/12
        (r'\b(19|20)\d{2}\b', 'year'),               # 1990, 2024
        (r'\b\d+%', 'percentage'),                   # 50%, 100%
        (r'\b\d+(\.\d+)?\s*(dt|tnd|ÿØŸäŸÜÿßÿ±)\b', 'price'),  # 50dt
        (r'\b\d+\s*(dt|tnd|ÿØŸäŸÜÿßÿ±)\b', 'price'),     # 50 dt
    ]
    
    for pattern, pattern_type in patterns:
        matches = list(re.finditer(pattern, result_text, re. IGNORECASE))
        for match in reversed(matches):
            # V√©rifier que ce n'est pas d√©j√† un placeholder
            if 'PROT' in match.group():
                continue
            original_value = match.group()
            placeholder = f"PROT{_protection_counter}PROT"
            _protected_values[placeholder] = original_value
            _protected_values[placeholder.lower()] = original_value
            result_text = result_text[:match.start()] + placeholder + result_text[match.end():]
            _protection_counter += 1
    
    return result_text


def restore_protected_patterns(text):
    """
    Restaure les patterns prot√©g√©s apr√®s la conversion.
    """
    global _protected_values
    
    result = text
    
    # Restaurer tous les placeholders (en minuscule car le texte est converti en minuscule)
    for placeholder, original in _protected_values.items():
        result = result.replace(placeholder, original)
        result = result.replace(placeholder.lower(), original)
    
    return result


def convert_arabic_dates_to_latin(text):
    """
    Convertit les dates avec mois arabes vers le format latin.
    Ex: 2 Ÿà3 ŸÖÿßŸä 2025 -> 2 w 3 mai 2025
        30 ÿ£ŸÉÿ™Ÿàÿ®ÿ± -> 30 octobre
    """
    month_mapping = {
        'ŸäŸÜÿßŸäÿ±': 'janvier', 'ÿ¨ÿßŸÜŸÅŸä': 'janvier', 'ÿ¨ÿßŸÜŸÅŸäŸäŸá': 'janvier',
        'ŸÅÿ®ÿ±ÿßŸäÿ±':  'fevrier', 'ŸÅŸäŸÅÿ±Ÿä': 'fevrier',
        'ŸÖÿßÿ±ÿ≥': 'mars',
        'ÿ£ÿ®ÿ±ŸäŸÑ':  'avril', 'ÿßŸÅÿ±ŸäŸÑ': 'avril',
        'ŸÖÿßŸä': 'mai', 'ŸÖÿßŸäŸà': 'mai',
        'ŸäŸàŸÜŸäŸà': 'juin', 'ÿ¨ŸàÿßŸÜ': 'juin',
        'ŸäŸàŸÑŸäŸà': 'juillet', 'ÿ¨ŸàŸäŸÑŸäÿ©': 'juillet',
        'ÿ£ÿ∫ÿ≥ÿ∑ÿ≥': 'aout', 'ÿßŸàÿ™': 'aout',
        'ÿ≥ÿ®ÿ™ŸÖÿ®ÿ±': 'septembre', 'ÿ≥ÿ®ÿ™ÿßŸÖÿ®ÿ±': 'septembre',
        'ÿ£ŸÉÿ™Ÿàÿ®ÿ±': 'octobre', 'ÿßŸÉÿ™Ÿàÿ®ÿ±': 'octobre',
        'ŸÜŸàŸÅŸÖÿ®ÿ±': 'novembre', 'ŸÜŸàŸÅÿßŸÖÿ®ÿ±': 'novembre',
        'ÿØŸäÿ≥ŸÖÿ®ÿ±': 'decembre', 'ÿØŸäÿ≥ÿßŸÖÿ®ÿ±': 'decembre',
    }
    
    result = text
    
    # Convertir les mois
    for arabic, latin in month_mapping.items():
        result = result.replace(arabic, latin)
    
    # Convertir Ÿà en w (pour les dates)
    # Pattern: chiffre + Ÿà + chiffre
    result = re.sub(r'(\d)\s*Ÿà\s*(\d)', r'\1 w \2', result)
    
    # Convertir ŸÑŸÄ/ŸÑ en "lel" (pour les plages)
    result = re.sub(r'\s*[ŸÑŸêŸÄŸÑ]+\s*', ' lel ', result)
    
    return result
# ============================================
# GESTION DES PR√âFIXES ARABES
# ============================================

# Pr√©fixes arabes courants (ordre important - du plus long au plus court)
ARABIC_PREFIXES = [
    'ŸàÿßŸÑ',    # w + al (et le/la)
    'ÿ®ÿßŸÑ',    # b + al (avec le/la)
    'ŸÑŸÑ',     # l + al (pour le/la)
    'ŸÅÿßŸÑ',    # f + al (alors le/la)
    'ŸÉÿßŸÑ',    # k + al (comme le/la)
    'Ÿàÿ®',     # w + b (et avec)
    'ŸàŸÑ',     # w + l (et pour)
    'ÿßŸÑ',     # al (le/la)
    'Ÿà',      # w (et)
    'ÿ®',      # b (avec)
    'ŸÑ',      # l (pour)
    'ŸÅ',      # f (alors)
    'ŸÉ',      # k (comme)
]

# Traduction des pr√©fixes en Darija latin
PREFIX_TO_DARIJA = {
    'ŸàÿßŸÑ': 'wel_',
    'ÿ®ÿßŸÑ': 'bel_',
    'ŸÑŸÑ': 'lel_',
    'ŸÅÿßŸÑ': 'fel_',
    'ŸÉÿßŸÑ':  'kel_',
    'Ÿàÿ®': 'w_b',
    'ŸàŸÑ': 'w_l',
    'ÿßŸÑ': '',        # Article d√©fini - souvent omis en darija
    'Ÿà': 'w_',
    'ÿ®': 'b_',
    'ŸÑ': 'l_',
    'ŸÅ': 'f_',
    'ŸÉ':  'k_',
}


def separate_arabic_prefix(word):
    """
    S√©pare le pr√©fixe arabe du mot de base.
    
    Args:
        word:  Mot arabe potentiellement avec pr√©fixe
    
    Returns:
        tuple: (pr√©fixe_darija, mot_base) ou (None, mot_original)
    
    Exemples:
        ŸàÿßŸÑŸÖŸàÿ≥ŸäŸÇŸâ -> ('w_', 'ÿßŸÑŸÖŸàÿ≥ŸäŸÇŸâ') -> ensuite 'ÿßŸÑŸÖŸàÿ≥ŸäŸÇŸâ' -> 'mousika'
        Ÿàÿ≠ŸÑŸà -> ('w_', 'ÿ≠ŸÑŸà')
        ÿßŸÑÿ¨Ÿà -> ('', 'ÿ¨Ÿà')
    """
    for prefix in ARABIC_PREFIXES:
        if word.startswith(prefix) and len(word) > len(prefix):
            base_word = word[len(prefix):]
            darija_prefix = PREFIX_TO_DARIJA.get(prefix, '')
            
            # Cas sp√©cial: si le pr√©fixe est 'ÿßŸÑ' et le mot de base commence par une lettre solaire
            # on garde le mot tel quel pour le chercher dans le dictionnaire
            if prefix == 'ÿßŸÑ': 
                # V√©rifier si le mot avec 'ÿßŸÑ' est dans le dictionnaire
                if word in ARABIC_WORDS_TO_DARIJA_LATIN: 
                    return (None, word)
                # Sinon retourner le mot sans 'ÿßŸÑ'
                return ('', base_word)
            
            return (darija_prefix, base_word)
    
    return (None, word)


def transliterate_arabic_to_latin(text):
    """
    Convertit le texte arabe en caract√®res latins (Darija).
    G√®re les pr√©fixes arabes attach√©s aux mots.
    """
    words = text.split()
    result_words = []
    
    for word in words:
        # Extraire la ponctuation
        punctuation_before = ''
        punctuation_after = ''
        clean_word = word
        
        # Extraire ponctuation avant
        while clean_word and not (clean_word[0]. isalnum() or '\u0600' <= clean_word[0] <= '\u06FF'):
            punctuation_before += clean_word[0]
            clean_word = clean_word[1:]
        
        # Extraire ponctuation apr√®s
        while clean_word and not (clean_word[-1].isalnum() or '\u0600' <= clean_word[-1] <= '\u06FF'):
            punctuation_after = clean_word[-1] + punctuation_after
            clean_word = clean_word[:-1]
        
        if not clean_word:
            if punctuation_before or punctuation_after:
                result_words.append(punctuation_before + punctuation_after)
            continue
        
        # V√©rifier si c'est un mot arabe
        if re.search(r'[\u0600-\u06FF]', clean_word):
            
            # 1. Chercher d'abord le mot complet dans le dictionnaire
            if clean_word in ARABIC_WORDS_TO_DARIJA_LATIN:
                transliterated = ARABIC_WORDS_TO_DARIJA_LATIN[clean_word]
                result_words.append(punctuation_before + transliterated + punctuation_after)
                continue
            
            # 2.  Essayer de s√©parer le pr√©fixe
            prefix_darija, base_word = separate_arabic_prefix(clean_word)
            
            if prefix_darija is not None:
                # Chercher le mot de base dans le dictionnaire
                if base_word in ARABIC_WORDS_TO_DARIJA_LATIN:
                    transliterated = prefix_darija + ARABIC_WORDS_TO_DARIJA_LATIN[base_word]
                    # Nettoyer les underscores en trop
                    transliterated = transliterated.replace('_', ' ').strip()
                    transliterated = re.sub(r'\s+', ' ', transliterated)
                    result_words. append(punctuation_before + transliterated + punctuation_after)
                    continue
                
                # Essayer sans le 'ÿßŸÑ' si pr√©sent
                if base_word. startswith('ÿßŸÑ') or base_word.startswith('ÿßŸÑ'):
                    base_without_al = base_word[2: ] if base_word.startswith('ÿßŸÑ') else base_word[2:]
                    if base_without_al in ARABIC_WORDS_TO_DARIJA_LATIN:
                        transliterated = prefix_darija + ARABIC_WORDS_TO_DARIJA_LATIN[base_without_al]
                        transliterated = transliterated.replace('_', ' ').strip()
                        transliterated = re.sub(r'\s+', ' ', transliterated)
                        result_words.append(punctuation_before + transliterated + punctuation_after)
                        continue
            
            # 3. Translitt√©ration lettre par lettre en dernier recours
            transliterated = ''
            for char in clean_word:
                if char in ARABIC_TO_LATIN:
                    transliterated += ARABIC_TO_LATIN[char]
                else:
                    transliterated += char
            
            result_words.append(punctuation_before + transliterated + punctuation_after)
        
        else:
            # Mot non-arabe, garder tel quel
            result_words.append(word)
    
    return ' '. join(result_words)

def is_arabic_text(text):
    """
    V√©rifie si le texte contient principalement des caract√®res arabes. 
    """
    arabic_chars = len(re.findall(r'[\u0600-\u06FF]', text))
    total_chars = len(re.findall(r'\w', text))
    
    if total_chars == 0:
        return False
    
    return arabic_chars / total_chars > 0.3  # Plus de 30% de caract√®res arabes

def normalize_to_darija(text):
    """
    Normalise le texte vers le Darija tunisien.
    """
    text_lower = text.lower()
    words = text_lower.split()
    normalized_words = []
    
    for word in words:
        clean_word = re.sub(r'[^\w\s]', '', word)
        punctuation = word[len(clean_word):] if len(word) > len(clean_word) else ''
        
        if not clean_word:
            continue
        
        # √âTAPE 1: Convertir les chiffres Darija vers lettres
        converted_word = convert_darija_numbers_smart(clean_word)
        
        if converted_word in KEEP_AS_IS:
            normalized_words.append(converted_word + punctuation)
            continue
        
        # √âTAPE 2: V√©rifier Darija normalization
        if converted_word in DARIJA_NORMALIZATION:
            normalized_words.append(DARIJA_NORMALIZATION[converted_word] + punctuation)
            continue
        
        # √âTAPE 3: V√©rifier Fran√ßais -> Darija
        if clean_word in FRENCH_TO_DARIJA:
            normalized_words.append(FRENCH_TO_DARIJA[clean_word] + punctuation)
            continue
            
        # √âTAPE 4: V√©rifier Arabe -> Darija (MODIFI√â)
        if clean_word in ARABIC_WORDS_TO_DARIJA_LATIN:
            normalized_words.append(ARABIC_WORDS_TO_DARIJA_LATIN[clean_word] + punctuation)
            continue
        
        # √âTAPE 5: Garder le mot converti
        normalized_words.append(converted_word + punctuation)
    
    return ' '.join(normalized_words)

def normalize_arabic_chars(text):
    """Normalise les caract√®res arabes."""
    # Supprimer diacritiques arabes
    arabic_diacritics = re.compile(r'[\u064B-\u065F\u0670]')
    text = re.sub(arabic_diacritics, '', text)
    
    # Normaliser caract√®res arabes
    replacements = {
        'ÿ£': 'ÿß', 'ÿ•': 'ÿß', 'ÿ¢': 'ÿß',
        'Ÿâ': 'Ÿä', 'ÿ©': 'Ÿá',
        'ÿ§': 'ÿ°', 'ÿ¶': 'ÿ°'
    }
    for ar, repl in replacements.items():
        text = text.replace(ar, repl)
    
    return text

def clean_special_characters(text):
    """
    Nettoie les caract√®res sp√©ciaux (guillemets, apostrophes, tirets, etc.)
    Couvre TOUTES les variantes possibles d'apostrophes. 
    """
    if not text:
        return text
    
    # Liste exhaustive de toutes les apostrophes possibles
    apostrophes = [
        '\u0027',  # ' APOSTROPHE
        '\u2019',  # ' RIGHT SINGLE QUOTATION MARK
        '\u2018',  # ' LEFT SINGLE QUOTATION MARK
        '\u02BC',  #  º MODIFIER LETTER APOSTROPHE
        '\u02B9',  #  π MODIFIER LETTER PRIME
        '\u0060',  # ` GRAVE ACCENT
        '\u00B4',  # ¬¥ ACUTE ACCENT
        '\u2032',  # ‚Ä≤ PRIME
        '\u2035',  # ‚Äµ REVERSED PRIME
        '\uFF07',  # Ôºá FULLWIDTH APOSTROPHE
        '\u02BB',  #  ª MODIFIER LETTER TURNED COMMA
        '\u02CA',  # Àä MODIFIER LETTER ACUTE ACCENT
        '\u02CB',  # Àã MODIFIER LETTER GRAVE ACCENT
    ]
    
    # Remplacer toutes les apostrophes par l'apostrophe standard
    for apos in apostrophes:
        text = text.replace(apos, "'")
    
    # Autres remplacements
    replacements = {
        # Guillemets
        '¬´':  '',
        '¬ª': '',
        '"': '',
        '"':  '',
        '‚Äû': '',
        '"': '',
        
        # Tirets
        '‚Äî': '-',
        '‚Äì': '-',
        '‚àí': '-',
        
        # Espaces sp√©ciaux
        '\u00a0': ' ',  # Non-breaking space
        '\u200b': '',   # Zero-width space
        '\u200c': '',   # Zero-width non-joiner
        '\u200d': '',   # Zero-width joiner
        '\ufeff': '',   # BOM
        
        # Autres
        '‚Ä¶': '...',
    }
    
    for old, new in replacements.items():
        text = text.replace(old, new)
    
    return text


def clean_punctuation(text):
    """
    Nettoie la ponctuation du texte. 
    Options: 
    - Supprimer toute la ponctuation
    - OU garder seulement certains caract√®res utiles
    """
    if not text:
        return text
    
    # Option 1: Supprimer TOUTE la ponctuation
    # Garder seulement:  lettres, chiffres, espaces
    text = re.sub(r'[^\w\s]', ' ', text)
    
    # Nettoyer les espaces multiples
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text
# ============================================
# GESTION DES CONTRACTIONS FRAN√áAISES
# ============================================
def expand_french_contractions(text):
    """
    Traite les contractions fran√ßaises (mots avec apostrophe).
    
    √âtape 1: Remplace les expressions compl√®tes (d'√©lectricit√© ‚Üí dhaw)
    √âtape 2: S√©pare les contractions restantes (l'eau ‚Üí l eau)
    """
    result = text
    
    # 1. Expressions compl√®tes avec contractions ‚Üí traduction directe
    full_expressions = {
        # √âlectricit√© / Services
        "d'√©lectricit√©": "dhaw",
        "d'electricit√©": "dhaw",
        "d'electricite": "dhaw",
        "d'internet": "internet",
        "d'eau": "ma",
        
        # Lieux avec article
        "l'eau": "el ma",
        "l'√©cole": "el madrsa",
        "l'h√¥pital": "el sbitar",
        "l'a√©roport": "el matar",
        "l'h√¥tel": "el hotel",
        "l'universit√©": "el fac",
        "l'√©glise": "el knisa",
        "l'entr√©e": "el dkhoul",
        "l'√©v√©nement": "el event",
        
        # Expressions courantes
        "aujourd'hui": "lyoum",
        "d'accord": "mwefek",
        "quelqu'un": "wahed",
        "quelqu'une": "wahda",
        "c'est-√†-dire": "yaani",
        "n'est-ce pas": "mouch keka",
        "s'il vous pla√Æt": "aychek",
        "s'il te pla√Æt": "aychek",
        
        # C'est / C'√©tait
        "c'est": "howa",
        "c'√©tait": "ken",
    }
    
    for expression, replacement in full_expressions. items():
        pattern = re.compile(re.escape(expression), re.IGNORECASE)
        result = pattern. sub(replacement, result)
    
    # 2. Contractions restantes ‚Üí s√©parer en deux mots
    simple_contractions = [
        ("d'", "de "),
        ("l'", "el "),
        ("j'", "ena "),
        ("m'", "m "),
        ("t'", "t "),
        ("s'", "s "),
        ("n'", "n "),
        ("qu'", "qu "),
    ]
    
    for contraction, expansion in simple_contractions:
        result = re. sub(re.escape(contraction), expansion, result, flags=re.IGNORECASE)
    
    return result

def normalize_text(text):
    """Pipeline de normalisation compl√®te vers Darija Latin."""
    if not text:
        return text
    
    # 1. Supprimer les emojis
    text = remove_emojis(text)
    
    # 2. Nettoyer les caract√®res sp√©ciaux (guillemets, apostrophes)
    text = clean_special_characters(text)
    
    # 3. Prot√©ger les nombres, heures, dates
    text = extract_protected_patterns(text)
    
    # 4. Traiter les contractions fran√ßaises
    text = expand_french_contractions(text)
    
    # 5. Translitt√©rer l'arabe vers le latin
    if is_arabic_text(text):
        text = transliterate_arabic_to_latin(text)
    
    # 6. Normaliser les caract√®res arabes
    text = normalize_arabic_chars(text)
    
    # 7. Convertir vers Darija normalis√©
    text = normalize_to_darija(text)
    
    # 8. Restaurer les patterns prot√©g√©s
    text = restore_protected_patterns(text)
    
    # 9. Convertir les dates arabes en latin (si la fonction existe)
    if 'convert_arabic_dates_to_latin' in dir():
        text = convert_arabic_dates_to_latin(text)
    
    # 10. NOUVEAU: Nettoyer la ponctuation
    text = clean_punctuation(text)
    
    # 11. Nettoyer espaces finaux
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text

def detect_language(text):
    """D√©tecte la langue originale du texte."""
    arabic_chars = len(re.findall(r'[\u0600-\u06FF]', text))
    latin_chars = len(re.findall(r'[a-zA-Z]', text))
    has_darija_numbers = any(c in text for c in ['3', '7', '9', '5', '2'])
    
    if arabic_chars > latin_chars:
        return 'ar'
    elif has_darija_numbers:
        return 'da'
    elif any(w in text. lower() for w in ['le', 'la', 'les', 'un', 'une', 'est', 'sont', 'avec']):
        return 'fr'
    elif latin_chars > 0:
        return 'da'  # Darija en caract√®res latins
    return 'da'


# ============================================
# 3. DATA AUGMENTATION
# ============================================
SYNONYMS_DARIJA = {
    'raw3a': ['hbel', 'rawaa', 'momtez'],
    'behi': ['mezyen', 'bnin', 'temem'],
    '5ayeb': ['mouch behi', 'fdhiha'],
}


def augment_with_synonyms(text):
    """Remplace al√©atoirement des mots par leurs synonymes en Darija."""
    words = text.split()
    augmented_words = []
    
    for word in words:
        if word in SYNONYMS_DARIJA and random.random() > 0.5:
            augmented_words. append(random.choice(SYNONYMS_DARIJA[word]))
        else:
            augmented_words. append(word)
    
    return ' '.join(augmented_words)


def augment_by_deletion(text, p=0.1):
    """Supprime al√©atoirement des mots."""
    words = text.split()
    if len(words) <= 3:
        return text
    return ' '.join([w for w in words if random.random() > p])


def augment_by_swap(text):
    """√âchange al√©atoirement deux mots adjacents."""
    words = text. split()
    if len(words) < 2:
        return text
    idx = random.randint(0, len(words) - 2)
    words[idx], words[idx + 1] = words[idx + 1], words[idx]
    return ' '.join(words)


def generate_augmented_samples(text, num_augmentations=3):
    """G√©n√®re plusieurs variations d'un texte."""
    augmentations = [text]
    
    for _ in range(num_augmentations):
        aug_type = random.choice(['synonym', 'deletion', 'swap'])
        if aug_type == 'synonym':
            augmentations.append(augment_with_synonyms(text))
        elif aug_type == 'deletion':
            augmentations.append(augment_by_deletion(text))
        else:
            augmentations.append(augment_by_swap(text))
    
    return list(set(augmentations))


# ============================================
# 4. PIPELINE COMPLET
# ============================================
def process_post(post, augment=False, num_augmentations=2):
    """Pipeline complet de traitement d'un post."""
    text = post.get('text', '')
    
    # NOUVEAU:  Nettoyer les caract√®res sp√©ciaux d√®s le d√©but
    text = clean_special_characters(text)
    
    # √âtape 1: Extraire les emojis ET leur sentiment
    emoji_data = extract_emoji_sentiment(text)
    
    # √âtape 2: D√©tecter la langue originale
    original_lang = detect_language(text)
    
    # √âtape 3: Normaliser vers Darija
    clean_text = normalize_text(text)
    
    # Cr√©er le post enrichi
    processed_post = post.copy()
    processed_post. update({
        'original_text': post.get('text', ''),  # Garder l'original non modifi√©
        'clean_text': clean_text,
        'original_lang': original_lang,
        'normalized_lang': 'darija',
        'emoji_sentiment': emoji_data,
    })
    
    results = [processed_post]
    
    # √âtape 4: Data Augmentation
    if augment:
        augmented_texts = generate_augmented_samples(clean_text, num_augmentations)
        for aug_text in augmented_texts[1:]: 
            aug_post = processed_post.copy()
            aug_post['clean_text'] = aug_text
            aug_post['is_augmented'] = True
            results.append(aug_post)
    
    return results

# ============================================
# 5.  TRAITEMENT DU FICHIER FINAL_EVALUATION_SET
# ============================================
def process_evaluation_data(input_path, output_path, augment=False, num_augmentations=2):
    """
    Traite le fichier final_evaluation_set.json et sauvegarde les r√©sultats. 
    
    Args:
        input_path: Chemin vers le fichier d'entr√©e JSON
        output_path: Chemin vers le fichier de sortie JSON
        augment: Activer l'augmentation de donn√©es
        num_augmentations: Nombre de variations √† g√©n√©rer
    """
    
    print("=" * 70)
    print("üöÄ SOCIALPULSE MONASTIR - Preprocessing Pipeline")
    print("=" * 70)
    
    # V√©rifier que le fichier existe
    if not os.path.exists(input_path):
        print(f"‚ùå Erreur: Fichier non trouv√©: {input_path}")
        return None
    
    # Charger les donn√©es
    print(f"\nüìÇ Chargement des donn√©es depuis: {input_path}")
    with open(input_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"‚úÖ {len(data)} posts charg√©s")
    
    # Statistiques
    stats = {
        'total_input': len(data),
        'total_output': 0,
        'by_original_lang': {'ar': 0, 'fr': 0, 'da': 0},
        'by_emoji_sentiment': {'positive': 0, 'negative': 0, 'neutral': 0},
        'posts_with_emojis': 0,
        'total_emojis_found': 0,
        'augmented_samples': 0
    }
    
    # Traiter chaque post
    print(f"\nüîÑ Traitement en cours...")
    all_results = []
    
    for i, post in enumerate(data):
        # Traitement
        results = process_post(post, augment=augment, num_augmentations=num_augmentations)
        
        for result in results:
            all_results.append(result)
            
            # Mise √† jour des statistiques
            lang = result.get('original_lang', 'da')
            stats['by_original_lang'][lang] = stats['by_original_lang']. get(lang, 0) + 1
            
            emoji_sent = result['emoji_sentiment']['dominant_sentiment']
            stats['by_emoji_sentiment'][emoji_sent] += 1
            
            if result['emoji_sentiment']['emoji_count'] > 0:
                stats['posts_with_emojis'] += 1
                stats['total_emojis_found'] += result['emoji_sentiment']['emoji_count']
            
            if result. get('is_augmented'):
                stats['augmented_samples'] += 1
        
        # Afficher la progression
        if (i + 1) % 10 == 0 or i == 0:
            print(f"   Trait√©: {i + 1}/{len(data)} posts")
    
    stats['total_output'] = len(all_results)
    
    # Cr√©er le dossier de sortie si n√©cessaire
    output_dir = os.path.dirname(output_path)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    # Sauvegarder les r√©sultats
    print(f"\nüíæ Sauvegarde des r√©sultats vers: {output_path}")
    with open(output_path, 'w', encoding='utf-8') as f:
        json. dump(all_results, f, ensure_ascii=False, indent=2)
    
    print(f"‚úÖ {len(all_results)} posts sauvegard√©s")
    
    # Afficher les statistiques
    print("\n" + "=" * 70)
    print("üìä STATISTIQUES")
    print("=" * 70)
    
    print(f"\nüìå Posts trait√©s:")
    print(f"   ‚Ä¢ Input: {stats['total_input']} posts")
    print(f"   ‚Ä¢ Output: {stats['total_output']} posts")
    if augment:
        print(f"   ‚Ä¢ Augment√©s: {stats['augmented_samples']} nouveaux samples")
    
    print(f"\nüåç R√©partition par langue originale:")
    for lang, count in stats['by_original_lang'].items():
        if count > 0:
            pct = (count / stats['total_output']) * 100
            bar = "‚ñà" * int(pct / 5)
            print(f"   ‚Ä¢ {lang}: {count} ({pct:.1f}%) {bar}")
    
    print(f"\nüòÄ Emojis:")
    print(f"   ‚Ä¢ Posts avec emojis: {stats['posts_with_emojis']}")
    print(f"   ‚Ä¢ Total emojis trouv√©s: {stats['total_emojis_found']}")
    
    print(f"\nüìä Sentiment (bas√© sur emojis):")
    print(f"   ‚Ä¢ ‚úÖ Positif: {stats['by_emoji_sentiment']['positive']}")
    print(f"   ‚Ä¢ ‚ùå N√©gatif: {stats['by_emoji_sentiment']['negative']}")
    print(f"   ‚Ä¢ ‚ö™ Neutre: {stats['by_emoji_sentiment']['neutral']}")
    
    # Afficher quelques exemples
    print("\n" + "=" * 70)
    print("üìù EXEMPLES DE R√âSULTATS")
    print("=" * 70)
    
    for i, result in enumerate(all_results[:5]):
        print(f"\n{'‚îÄ'*70}")
        print(f"Post #{i+1}")
        print(f"{'‚îÄ'*70}")
        original = result.get('original_text', result.get('text', ''))[:60]
        print(f"üìå Original: {original}...")
        print(f"üîÑ Normalis√©: {result['clean_text'][:60]}...")
        print(f"üåç Langue: {result['original_lang']} ‚Üí darija")
        print(f"üòÄ Sentiment emoji: {result['emoji_sentiment']['dominant_sentiment']} (score: {result['emoji_sentiment']['avg_score']})")
        if result['emoji_sentiment']['emojis']:
            emojis = [(e['emoji'], e['label_darija']) for e in result['emoji_sentiment']['emojis'][:4]]
            print(f"   Emojis: {emojis}")
    
    print("\n" + "=" * 70)
    print("‚úÖ TRAITEMENT TERMIN√â!")
    print("=" * 70)
    
    return all_results, stats


# ============================================
# MAIN - EX√âCUTION
# ============================================
if __name__ == "__main__":
    # D√©terminer le chemin de base (racine du projet)
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(script_dir)  # Remonter d'un niveau (de src/ vers racine)
    
    # Chemins des fichiers
    input_file = os.path.join(project_root, 'data', 'processed', 'final_evaluation_set.json')
    output_file = os.path.join(project_root, 'data', 'processed', 'result_after_validation.json')
    
    print(f"\nüìÅ Chemin d'entr√©e: {input_file}")
    print(f"üìÅ Chemin de sortie: {output_file}")
    
    # Traiter les donn√©es (sans augmentation pour la validation)
    results, stats = process_evaluation_data(
        input_path=input_file,
        output_path=output_file,
        augment=False,  # Mettre True pour activer l'augmentation
        num_augmentations=2
    )
    
    # Optionnel: G√©n√©rer aussi une version augment√©e
    print("\n" + "=" * 70)
    print("üìà G√©n√©ration du dataset augment√©...")
    print("=" * 70)
    
    output_augmented = os.path.join(project_root, 'data', 'processed', 'result_augmented.json')
    results_aug, stats_aug = process_evaluation_data(
        input_path=input_file,
        output_path=output_augmented,
        augment=True,
        num_augmentations=3
    )



# ============================================
# TESTS

# if __name__ == "__main__":

 #   print("=" * 60)
 #   print("TEST: Normalisation vers Darija Tunisien")
  #  print("=" * 60)
    
  #  test_posts = [
        # Darija original
    #    {"id": 1, "text": "El jaw fi monastir raw3a üòçüî• barcha ness fel plage! "},
        
        # Fran√ßais
   #     {"id": 2, "text": "La plage de Monastir est magnifique aujourd'hui!  üèñÔ∏è"},
        
        # Arabe standard
    #    {"id": 3, "text": "ÿßŸÑÿ∑ŸÇÿ≥ ÿ¨ŸÖŸäŸÑ ŸÅŸä ÿßŸÑŸÖŸÜÿ≥ÿ™Ÿäÿ± ÿßŸÑŸäŸàŸÖ ‚òÄÔ∏è"},
        
        # Mix
    #    {"id": 4, "text": "Panne de courant √† Khniss üò° barcha mochkla! "},
        
        # Darija avec variantes
      #  {"id": 5, "text": "Kifech el jaw lyoum?  Thama barcha ness fel b7ar"},
 #   ]
    
  #  for post in test_posts:
  #      print(f"\n{'='*60}")
  #      print(f"Post ID: {post['id']}")
  #      print(f"Original: {post['text']}")
        
    #    results = process_post(post, augment=False)
    #    result = results[0]
    #    
   #     print(f"Langue originale: {result['original_lang']}")
    #    print(f"Normalis√© (Darija): {result['clean_text']}")
    #    print(f"Emoji sentiment: {result['emoji_sentiment']['dominant_sentiment']}")
       # if result['emoji_sentiment']['emojis']:
       #     print(f"Emojis: {[(e['emoji'], e['label_darija']) for e in result['emoji_sentiment']['emojis']]}")
    
  #  print(f"\n{'='*60}")
  #  print("TEST: Data Augmentation en Darija")
  #  print("=" * 60)
    
   # sample = {"id": 99, "text": "El jaw raw3a barcha fi mestir! "}
  #  results = process_post(sample, augment=True, num_augmentations=3)
    
   # print(f"\nOriginal: {sample['text']}")
   # for i, r in enumerate(results):
   #     aug_label = " (augment√©)" if r. get('is_augmented') else " (original)"
   #     print(f"  {i+1}. {r['clean_text']}{aug_label}")
        # ============================================


        # ============================================

    
    print("=" * 70)
    print("üîç DIAGNOSTIC - Probl√®me d'√©lectricit√©")
    print("=" * 70)
    
    # Texte de test
    test_text = "Coupures d'√©lectricit√©, ce dimanche, √† Monastir"
    
    # 1. V√©rifier le type d'apostrophe
    print("\n1Ô∏è‚É£ ANALYSE DES CARACT√àRES :")
    print(f"   Texte: {test_text}")
    for i, char in enumerate(test_text):
        code = ord(char)
        if code > 127 or char in ["'", "'", "'", " º", "¬¥", "`", "'"]:
            print(f"   Position {i}: '{char}' ‚Üí Unicode: U+{code:04X} ({code})")
    
    # 2. V√©rifier si clean_special_characters existe
    print("\n2Ô∏è‚É£ V√âRIFICATION DES FONCTIONS :")
    functions_to_check = [
        'clean_special_characters',
        'expand_french_contractions', 
        'normalize_text',
        'normalize_to_darija'
    ]
    for func_name in functions_to_check:
        exists = func_name in dir()
        print(f"   {func_name}: {'‚úÖ Existe' if exists else '‚ùå MANQUANTE'}")
    
    # 3. V√©rifier le dictionnaire
    print("\n3Ô∏è‚É£ V√âRIFICATION DU DICTIONNAIRE FRENCH_TO_DARIJA :")
    words_to_check = ['√©lectricit√©', 'electricite', 'coupure', 'coupures', 'dimanche']
    for word in words_to_check:
        exists = word in FRENCH_TO_DARIJA
        value = FRENCH_TO_DARIJA. get(word, 'NON TROUV√â')
        print(f"   '{word}': {'‚úÖ' if exists else '‚ùå'} ‚Üí {value}")
    
    # 4. Test √©tape par √©tape
    print("\n4Ô∏è‚É£ TEST √âTAPE PAR √âTAPE :")
    
    text = test_text
    print(f"   Original: {text}")
    
    # √âtape:  clean_special_characters
    if 'clean_special_characters' in dir():
        text = clean_special_characters(text)
        print(f"   Apr√®s clean_special_characters: {text}")
    else:
        print("   ‚ùå clean_special_characters N'EXISTE PAS!")
    
    # √âtape: expand_french_contractions  
    if 'expand_french_contractions' in dir():
        text = expand_french_contractions(text)
        print(f"   Apr√®s expand_french_contractions: {text}")
    else:
        print("   ‚ùå expand_french_contractions N'EXISTE PAS!")
    
    # √âtape: normalize_to_darija
    text_lower = text.lower()
    print(f"   Apr√®s lowercase: {text_lower}")
    
    text = normalize_to_darija(text_lower)
    print(f"   Apr√®s normalize_to_darija: {text}")
    
    # 5. Test final
    print("\n5Ô∏è‚É£ TEST FINAL normalize_text() :")
    final_result = normalize_text(test_text)
    print(f"   Input:   {test_text}")
    print(f"   Output: {final_result}")
    
    print("\n" + "=" * 70)