"""
SocialPulse Monastir - Mod√®le Naive Bayes
=========================================
Entra√Ænement d'un mod√®le Naive Bayes pour l'analyse de sentiment. 

"""

import os
import json
import pickle
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report

# ============================================================
# CONFIGURATION
# ============================================================

SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(SCRIPT_DIR)
DATA_FILE = os.path.join(PROJECT_ROOT, 'data', 'processed', 'augmented_dataset.json')
MODEL_FILE = os.path. join(PROJECT_ROOT, 'models', 'sentiment_model. pkl')


def load_data():
    """Charge les donn√©es d'entra√Ænement."""
    # Essayer le dataset augment√© d'abord
    if os.path.exists(DATA_FILE):
        with open(DATA_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
    else:
        # Sinon, utiliser le dataset de base
        base_file = os.path.join(PROJECT_ROOT, 'data', 'processed', 'training_dataset.json')
        with open(base_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
    
    texts = [item['text'] for item in data]
    labels = [item['label'] for item in data]
    
    return texts, labels


def train_model():
    """Entra√Æne le mod√®le Naive Bayes."""
    print("=" * 60)
    print("SOCIALPULSE - Entra√Ænement Mod√®le Naive Bayes")
    print("=" * 60)
    
    # Charger les donn√©es
    print("\nüìÇ Chargement des donn√©es...")
    texts, labels = load_data()
    print("‚úÖ " + str(len(texts)) + " √©chantillons charg√©s")
    
    # Compter par classe
    from collections import Counter
    counts = Counter(labels)
    print("   ‚úÖ Positive: " + str(counts. get('positive', 0)))
    print("   ‚ùå Negative: " + str(counts.get('negative', 0)))
    print("   ‚ö™ Neutral:   " + str(counts.get('neutral', 0)))
    
    # Split train/test
    X_train, X_test, y_train, y_test = train_test_split(
        texts, labels, test_size=0.2, random_state=42, stratify=labels
    )
    
    print("\nüîÑ Vectorisation TF-IDF...")
    vectorizer = TfidfVectorizer(
        max_features=5000,
        ngram_range=(1, 2),
        min_df=2
    )
    
    X_train_vec = vectorizer.fit_transform(X_train)
    X_test_vec = vectorizer.transform(X_test)
    
    print("‚úÖ Vocabulaire:  " + str(len(vectorizer.vocabulary_)) + " mots")
    
    # Entra√Æner
    print("\nüîÑ Entra√Ænement Naive Bayes...")
    model = MultinomialNB(alpha=0.1)
    model.fit(X_train_vec, y_train)
    print("‚úÖ Mod√®le entra√Æn√©!")
    
    # √âvaluer
    print("\nüìä √âvaluation...")
    y_pred = model. predict(X_test_vec)
    accuracy = accuracy_score(y_test, y_pred)
    
    print("\n" + "=" * 60)
    print("üìä R√âSULTATS")
    print("=" * 60)
    print("   Accuracy: " + str(round(accuracy * 100, 1)) + "%")
    print("\n" + classification_report(y_test, y_pred))
    
    # Sauvegarder
    print("\nüíæ Sauvegarde du mod√®le...")
    
    # Cr√©er le dossier models si n√©cessaire
    os.makedirs(os.path.dirname(MODEL_FILE), exist_ok=True)
    
    model_data = {
        'model': model,
        'vectorizer': vectorizer,
        'accuracy': accuracy
    }
    
    with open(MODEL_FILE, 'wb') as f:
        pickle. dump(model_data, f)
    
    print("‚úÖ Mod√®le sauvegard√©:  " + MODEL_FILE)
    
    return model, vectorizer, accuracy


if __name__ == "__main__": 
    train_model()